{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import data\n",
    "from recurrent_attention import RecurrentAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overhead stuff\n",
    "\n",
    "Helper functions for batching, resetting hidden states, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "eval_batch_size = 10\n",
    "batch_size = 74\n",
    "seq_len = 18\n",
    "dropout = 0.1\n",
    "clip = 1\n",
    "lr = 0.1\n",
    "warmup_steps = 7\n",
    "decay_factor = 0.5  # Higher => faster learning rate decay\n",
    "smooth_labels = False\n",
    "\n",
    "epochs = 50\n",
    "log_interval = 100  # Print log every `log_interval` batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "embed_size = 256\n",
    "encode_size = 128\n",
    "h_size = 64\n",
    "attn_out_size = 128\n",
    "decode_size = 256\n",
    "n_layers = 2\n",
    "attn_rnn_layers = 1\n",
    "bidirectional_attn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from sequential data, `batchify` arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n",
    "def batchify(data, batch_size):\n",
    "    # Work out how cleanly we can divide the dataset into batches\n",
    "    nbatches = data.size(0) // batch_size\n",
    "    # Trim off any extra elements that wouldn't cleanly fit\n",
    "    data = data.narrow(0, 0, nbatches * batch_size)\n",
    "    # Evenly divide the data across the batches\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    return data\n",
    "\n",
    "# Wraps hidden states into new Variables to detach them from their history\n",
    "def repackage_hidden(h):\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "# `get_batch` subdivides the source data into chunks of the specified length.\n",
    "# E.g., using the example for the `batchify` function above and a length of 2,\n",
    "# we'd get the following two Variables for i = 0:\n",
    "# ┌ a g m s ┐ ┌ b h n t ┐\n",
    "# └ b h n t ┘ └ c i o u ┘\n",
    "# Note that despite the name of the function, the subdivison of data is not\n",
    "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
    "# by the `batchify` function. The chunks are along dimension 0, corresponding\n",
    "# to the `seq_len` dimension in the LSTM.\n",
    "def get_batch(source, i, seq_len, evaluate = False):\n",
    "    seq_len = min(seq_len, len(source) - 1 - i)\n",
    "    data = Variable(source[i : i+seq_len], volatile = evaluate)\n",
    "    target = Variable(source[i+1 : i+1+seq_len].view(-1), volatile = evaluate)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label smoothing class for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, padding_idx = None, smoothing = 0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        if self.padding_idx is not None:\n",
    "            true_dist[:, self.padding_idx] = 0\n",
    "            mask = torch.nonzero(target.data == self.padding_idx)\n",
    "            if mask.dim() > 0:\n",
    "                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate scheduler that sets the learning rate factor according to:\n",
    "\n",
    "$$\\text{lr} = d_{\\text{model}}^{-0.5}\\cdot\\min{(\\text{epoch}^{-0.5}, \\text{epoch}\\cdot\\text{warmup}^{-1.5})}$$\n",
    "\n",
    "This corresponds to increasing the learning rate linearly for the first $\\text{warmup}$ epochs, then decreasing it proportionally to the inverse square root of the epoch number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler(h_size, warmup, optimizer):\n",
    "    lrate = lambda e: h_size**(-0.5) * min((e+1)**(-decay_factor), (e+1) * warmup**(-(decay_factor+1)))\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-707598013668>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m )])\n",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ce5706c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrate = lambda factor, h_size, warmup: lambda e: factor*(h_size**(-0.5) * min(e**(-decay_factor), e * warmup**(-(decay_factor+1))))\n",
    "opts = [\n",
    "    lrate(2*lr, embed_size, warmup_steps), \n",
    "    lrate(lr, embed_size*2, warmup_steps),\n",
    "    lrate(lr, embed_size, warmup_steps*3),\n",
    "    lrate(lr, embed_size, warmup_steps),\n",
    "]\n",
    "plt.plot(np.arange(1, epochs+1), [[opt(i) for opt in opts] for i in range(1, epochs+1)])\n",
    "plt.legend([\"%.1f:%d:%d\", \"%.1f:%d:%d\", \"%.1f:%d:%d\", \"%.1f:%d:%d\" % (\n",
    "    2*lr, embed_size, warmup_steps,\n",
    "    lr, embed_size*2, warmup_steps,\n",
    "    lr, embed_size, warmup_steps*3,\n",
    "    lr, embed_size, warmup_steps,\n",
    ")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.Corpus('./data/ptb')\n",
    "ntokens = len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab,\n",
    "                 embed_size, encode_size, h_size,\n",
    "                 attn_out_size, decode_size, n_layers,\n",
    "                 attn_rnn_layers, bidirectional_attn,\n",
    "                 tie_wts = True, dropout = 0.1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.embed_size = embed_size\n",
    "        self.encode_size = encode_size\n",
    "        self.h_size = h_size\n",
    "        self.attn_out_size = attn_out_size\n",
    "        self.decode_size = decode_size\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_rnn_layers = attn_rnn_layers\n",
    "        self.bidirectional_attn = bidirectional_attn\n",
    "        self.tie_wts = tie_wts\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding = nn.Embedding(src_vocab, embed_size)\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size = embed_size, hidden_size = encode_size,\n",
    "            num_layers = n_layers, dropout = dropout\n",
    "        )\n",
    "        self.attn = RecurrentAttention(\n",
    "            in_size = encode_size, h_size = h_size, out_size = attn_out_size,\n",
    "            dropout = dropout, num_rnn_layers = attn_rnn_layers,\n",
    "            attn_act_fn = 'Tanh', bidirectional = bidirectional_attn\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size = attn_out_size, hidden_size = decode_size,\n",
    "            num_layers = n_layers, dropout = dropout\n",
    "        )\n",
    "        self.projection = nn.Linear(decode_size, tgt_vocab)\n",
    "        # Tie the embedding and projection matrix weights\n",
    "        if tie_wts and src_vocab == tgt_vocab and embed_size == decode_size:\n",
    "            self.embedding.weight = self.projection.weight\n",
    "        \n",
    "    def init(self):\n",
    "        for subnet in [self.encoder, self.decoder]:\n",
    "            for p in subnet.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    nn.init.xavier_normal(p)\n",
    "                else:\n",
    "                    p.data.fill_(0)\n",
    "        for p in self.linear.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform(p)\n",
    "            else:\n",
    "                p.data.fill_(0)\n",
    "        self.attn.init()\n",
    "        \n",
    "    def init_states(self, batch_size):\n",
    "        encoder_states = (\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.encode_size)),\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.encode_size))\n",
    "        )\n",
    "        attn_states = self.attn.init_rnn_states(batch_size)\n",
    "        decoder_states = (\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.decode_size)),\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.decode_size))\n",
    "        )\n",
    "        return encoder_states, attn_states, decoder_states\n",
    "    \n",
    "    def forward(self, inputs, states):\n",
    "        enc_states, attn_states, dec_states = states\n",
    "        relu = nn.ReLU()\n",
    "        log_softmax = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "        embeddings = self.embedding(inputs)\n",
    "        enc_out, new_enc_states = self.encoder(self.drop(embeddings))\n",
    "        attn_out, new_attn_states = self.attn(enc_out, attn_states)\n",
    "        dec_out, new_dec_states = self.decoder(relu(attn_out))\n",
    "        output = self.projection(dec_out)\n",
    "        if smooth_labels:\n",
    "            output = log_softmax(output)\n",
    "        return output, (new_enc_states, new_attn_states, new_dec_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model, criterion, optimizer, and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    ntokens, ntokens, embed_size, encode_size, h_size,\n",
    "    attn_out_size, decode_size, n_layers, attn_rnn_layers,\n",
    "    bidirectional_attn, dropout = dropout\n",
    ")\n",
    "if smooth_labels:\n",
    "    criterion = LabelSmoothing(ntokens, smoothing = 0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr = lr, betas = (0.9, 0.98), eps = 1e-9\n",
    ")\n",
    "lr_scheduler = get_lr_scheduler(embed_size, warmup_steps, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparams = sum([p.numel() for p in model.parameters()])\n",
    "print('Model parameters: %d' % nparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Ready the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = batchify(corpus.train, batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Use random length sequences\n",
    "    seq_lens = []\n",
    "    tot_len = 0\n",
    "    jitter = 0.15 * seq_len\n",
    "    while tot_len < train_data.size(0) - 2:\n",
    "        if train_data.size(0) - tot_len - 2 <= seq_len + jitter:\n",
    "            slen = train_data.size(0) - tot_len - 2\n",
    "        else:\n",
    "            slen = int(np.random.normal(seq_len, jitter))\n",
    "            if slen <= 0:\n",
    "                slen = seq_len    # eh\n",
    "            if tot_len + slen >= train_data.size(0) - jitter - 2:\n",
    "                slen = train_data.size(0) - tot_len - 2\n",
    "        seq_lens.append(slen)\n",
    "        tot_len += slen\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    # Initialize RNN states\n",
    "    states = model.init_states(batch_size)\n",
    "    # Prep metainfo\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch, i in enumerate(np.cumsum(seq_lens)):\n",
    "        # Get training data\n",
    "        data, targets = get_batch(train_data, i, seq_lens[batch])\n",
    "        # Repackage the hidden states\n",
    "        states = repackage_hidden(states) #model.init_states(batch_size)\n",
    "        # Zero out gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Run the model forward\n",
    "        output, _states = model(data, states)\n",
    "        if np.isnan(output.data).any():\n",
    "            return (0, data, targets, states, _states)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        if np.isnan(loss.data[0]):\n",
    "            return (1, data, targets, states, _states)\n",
    "        states = _states\n",
    "        # Propagate loss gradient backwards\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            # Save gradient statistics before they're changed cuz we'll be logging this batch\n",
    "            parameters = [p for p in model.parameters() if p.grad is not None]\n",
    "            # Calculate the largest (absolute) gradient of all elements in the model parameters\n",
    "            max_grad = max([p.grad.data.abs().max() for p in parameters])\n",
    "        total_norm = nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        # Scale the batch learning rate so that shorter sequences aren't \"stronger\"\n",
    "        scaled_lr = [\n",
    "            r * np.sqrt(seq_lens[batch] / seq_len) for r in lr_scheduler.get_lr()\n",
    "        ]\n",
    "        for param_group, r in zip(optimizer.param_groups, scaled_lr):\n",
    "            param_group['lr'] = r\n",
    "        # Adjust parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get some metainfo\n",
    "        total_loss += loss.data\n",
    "        lr = np.mean(scaled_lr)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            cur_loss = total_loss[0] / log_interval\n",
    "            print('b {:3d}/{:3d} >> {:6.1f} ms/b | lr: {:8.2g} | grad norm: {:4.2g} | max abs grad: {:8.2g} | loss: {:5.2f} | perp.: {:7.1f}'.format(\n",
    "                batch, len(seq_lens), elapsed * 1000/log_interval, lr, total_norm, max_grad, cur_loss, np.exp(cur_loss)\n",
    "            ))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    return (-1, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_src):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    states = model.init_states(eval_batch_size)\n",
    "    for i in range(0, data_src.size(0) - 1, seq_len):\n",
    "        # Get data\n",
    "        data, targets = get_batch(data_src, i, seq_len, evaluate = True)\n",
    "        # Repackage the hidden states\n",
    "        states = repackage_hidden(states) #model.init_states(eval_batch_size)\n",
    "        # Evaluate\n",
    "        output, states = model(data, states)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        total_loss += len(data) * loss.data\n",
    "    return total_loss[0] / len(data_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 114\n",
    "CAUSES = ['output', 'grad']\n",
    "for epoch in range(epochs):\n",
    "    lr_scheduler.step()\n",
    "    print('Epoch {:3d}) lr = {:0.4g}{}'.format(epoch+1, np.mean(lr_scheduler.get_lr()), ' (warmup)' if epoch < warmup_steps else ''))\n",
    "    start_time = time.time()\n",
    "    (stat, data, targets, states, nstates) = train()\n",
    "    if stat in list(range(len(CAUSES))):\n",
    "        c = CAUSES[stat]\n",
    "        n = (WIDTH - len(c) - 4) // 2\n",
    "        print('\\n' + (' '*n) + 'NaN ' + c)\n",
    "        break\n",
    "    elapsed = time.time() - start_time\n",
    "    val_loss = evaluate(val_data)\n",
    "    max_param = max([p.data.abs().max() for p in model.parameters() if p.grad is not None])\n",
    "    print('-' * WIDTH)\n",
    "    print('Elapsed time: {:5.2f} sec | max abs wt: {:5.2g} | valid_loss: {:5.2f} | valid_perplexity: {:8.2f}'.format(\n",
    "        elapsed, max_param, val_loss, np.exp(val_loss)\n",
    "    ))\n",
    "    print('=' * WIDTH)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stat in list(range(len(CAUSES))):\n",
    "    params = [p for p in model.parameters() if p.grad is not None]\n",
    "    print(any([np.isnan(p.data).any() for p in params]), any([np.isnan(p.grad.data).any() for p in params]))\n",
    "    \n",
    "    enc_states, attn_states, dec_states = states\n",
    "    relu = nn.ReLU()\n",
    "    log_softmax = nn.LogSoftmax(dim = -1)\n",
    "    \n",
    "    embeddings = model.embedding(data)\n",
    "    enc_out, new_enc_states = model.encoder(model.drop(embeddings))\n",
    "    attn_out, new_attn_states = model.attn(enc_out, attn_states)\n",
    "    dec_out, new_dec_states = model.decoder(relu(attn_out))\n",
    "    output = model.projection(dec_out)\n",
    "    \n",
    "    print([\n",
    "        np.isnan(p.data).any() for p in [embeddings, enc_out, attn_out, dec_out, output]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(test_data)\n",
    "print('test_loss: {:5.2f} | test_perplexity: {:8.2f}'.format(\n",
    "    test_loss, np.exp(test_loss)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some random words\n",
    "Just, like, y'know, as a test or whatever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "\n",
    "gstates = model.init_states(1)\n",
    "cur_word = Variable(torch.rand(1, 1).mul(ntokens).long(), volatile = True)\n",
    "gen_text = [int(cur_word)]\n",
    "\n",
    "for i in range(num_words):\n",
    "    output, hidden = model(cur_word, gstates)\n",
    "    word_weights = output.squeeze().exp()\n",
    "    word_idx = torch.multinomial(word_weights, 1).data[0]\n",
    "    gen_text.append(int(word_idx))\n",
    "    cur_word.data.fill_(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the words\n",
    "print(' '.join([corpus.dictionary.idx2word[i] for i in gen_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.grad is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grad = max([p.grad.data.abs().max() for p in params])\n",
    "max_param = max([p.data.abs().max() for p in params])\n",
    "max_param, max_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
