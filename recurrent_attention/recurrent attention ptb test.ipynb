{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import data\n",
    "from recurrent_attention import RecurrentAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overhead stuff\n",
    "\n",
    "Helper functions for batching, resetting hidden states, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "eval_batch_size = 10\n",
    "batch_size = 74\n",
    "seq_len = 18\n",
    "dropout = 0.1\n",
    "clip = 0.1\n",
    "lr = 0.005  #0.01\n",
    "lr_factor = 10  #1.618\n",
    "warmup_steps = 15\n",
    "smooth_labels = False\n",
    "\n",
    "epochs = 100\n",
    "log_interval = 100  # Print log every `log_interval` batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "embed_size = 256\n",
    "encode_size = 128\n",
    "h_size = 64\n",
    "attn_out_size = 128\n",
    "decode_size = 256\n",
    "n_layers = 2\n",
    "attn_rnn_layers = 1\n",
    "bidirectional_attn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from sequential data, `batchify` arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n",
    "def batchify(data, batch_size):\n",
    "    # Work out how cleanly we can divide the dataset into batches\n",
    "    nbatches = data.size(0) // batch_size\n",
    "    # Trim off any extra elements that wouldn't cleanly fit\n",
    "    data = data.narrow(0, 0, nbatches * batch_size)\n",
    "    # Evenly divide the data across the batches\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    return data\n",
    "\n",
    "# Wraps hidden states into new Variables to detach them from their history\n",
    "def repackage_hidden(h):\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "# `get_batch` subdivides the source data into chunks of the specified length.\n",
    "# E.g., using the example for the `batchify` function above and a length of 2,\n",
    "# we'd get the following two Variables for i = 0:\n",
    "# ┌ a g m s ┐ ┌ b h n t ┐\n",
    "# └ b h n t ┘ └ c i o u ┘\n",
    "# Note that despite the name of the function, the subdivison of data is not\n",
    "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
    "# by the `batchify` function. The chunks are along dimension 0, corresponding\n",
    "# to the `seq_len` dimension in the LSTM.\n",
    "def get_batch(source, i, seq_len, evaluate = False):\n",
    "    seq_len = min(seq_len, len(source) - 1 - i)\n",
    "    data = Variable(source[i : i+seq_len], volatile = evaluate)\n",
    "    target = Variable(source[i+1 : i+1+seq_len].view(-1), volatile = evaluate)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label smoothing class for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, padding_idx = None, smoothing = 0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        if self.padding_idx is not None:\n",
    "            true_dist[:, self.padding_idx] = 0\n",
    "            mask = torch.nonzero(target.data == self.padding_idx)\n",
    "            if mask.dim() > 0:\n",
    "                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate scheduler that sets the learning rate factor according to:\n",
    "\n",
    "$$\\text{lr} = d_{\\text{model}}^{-0.5}\\cdot\\min{(\\text{epoch}^{-0.5}, \\text{epoch}\\cdot\\text{warmup}^{-1.5})}$$\n",
    "\n",
    "This corresponds to increasing the learning rate linearly for the first $\\text{warmup}$ epochs, then decreasing it proportionally to the inverse square root of the epoch number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler(h_size, factor, warmup, optimizer):\n",
    "    lrate = lambda e: factor * (h_size**(-0.5) * min((e+1)**(-0.5), (e+1) * warmup**(-1.5)))\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e55f9d1cf8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e55d964780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrate = lambda factor, h_size, warmup: lambda e: factor*(h_size**(-0.5) * min(e**(-0.5), e * warmup**(-1.5)))\n",
    "opts = [\n",
    "    lrate(2, 512, 40), \n",
    "    lrate(1, 512, 80),\n",
    "    lrate(2, 256, 40),\n",
    "    lrate(lr_factor*lr, embed_size, warmup_steps),\n",
    "]\n",
    "plt.plot(np.arange(1, 200), [[opt(i) for opt in opts] for i in range(1, 200)])\n",
    "plt.legend([\"2:512:40\", \"1:512:80\", \"2:256:40\", \"%.2f:%d:%d\" % (lr_factor*lr, embed_size, warmup_steps)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.Corpus('./data/ptb')\n",
    "ntokens = len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab,\n",
    "                 embed_size, encode_size, h_size,\n",
    "                 attn_out_size, decode_size, n_layers,\n",
    "                 attn_rnn_layers, bidirectional_attn,\n",
    "                 project = True, dropout = 0.1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.embed_size = embed_size\n",
    "        self.encode_size = encode_size\n",
    "        self.h_size = h_size\n",
    "        self.attn_out_size = attn_out_size\n",
    "        self.decode_size = decode_size\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_rnn_layers = attn_rnn_layers\n",
    "        self.bidirectional_attn = bidirectional_attn\n",
    "        self.project = project\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embed = nn.Embedding(src_vocab, embed_size)\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size = embed_size, hidden_size = encode_size,\n",
    "            num_layers = n_layers, dropout = dropout\n",
    "        )\n",
    "        self.attn = RecurrentAttention(\n",
    "            in_size = encode_size, h_size = h_size, out_size = attn_out_size,\n",
    "            dropout = dropout, num_rnn_layers = attn_rnn_layers,\n",
    "            bidirectional = bidirectional_attn\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size = attn_out_size, hidden_size = decode_size,\n",
    "            num_layers = n_layers, dropout = dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(decode_size, tgt_vocab)\n",
    "        if project and src_vocab == tgt_vocab and embed_size == decode_size:\n",
    "            self.decoder.weight = self.embed.weight\n",
    "        \n",
    "    def init(self):\n",
    "        for subnet in [self.encoder, self.decoder]:\n",
    "            for p in subnet.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    nn.init.xavier_normal(p)\n",
    "                else:\n",
    "                    p.data.fill_(0)\n",
    "        for p in self.linear.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform(p)\n",
    "            else:\n",
    "                p.data.fill_(0)\n",
    "        self.attn.init()\n",
    "        \n",
    "    def init_states(self, batch_size):\n",
    "        encoder_states = (\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.encode_size)),\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.encode_size))\n",
    "        )\n",
    "        attn_states = self.attn.init_rnn_states(batch_size)\n",
    "        decoder_states = (\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.decode_size)),\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.decode_size))\n",
    "        )\n",
    "        return encoder_states, attn_states, decoder_states\n",
    "    \n",
    "    def forward(self, inputs, states):\n",
    "        enc_states, attn_states, dec_states = states\n",
    "        relu = nn.ReLU()\n",
    "        log_softmax = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "        embeddings = self.embed(inputs) * np.sqrt(self.embed_size)\n",
    "        enc_out, new_enc_states = self.encoder(self.drop(embeddings))\n",
    "        attn_out, new_attn_states = self.attn(enc_out, attn_states)\n",
    "        dec_out, new_dec_states = self.decoder(relu(attn_out))\n",
    "        output = self.linear(dec_out)\n",
    "        if smooth_labels:\n",
    "            output = log_softmax(output)\n",
    "        return output, (new_enc_states, new_attn_states, new_dec_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model, criterion, optimizer, and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    ntokens, ntokens, embed_size, encode_size, h_size,\n",
    "    attn_out_size, decode_size, n_layers, attn_rnn_layers,\n",
    "    bidirectional_attn, dropout = dropout\n",
    ")\n",
    "if smooth_labels:\n",
    "    criterion = LabelSmoothing(ntokens, smoothing = 0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr = lr, betas = (0.9, 0.98), eps = 1e-9\n",
    ")\n",
    "lr_scheduler = get_lr_scheduler(embed_size, lr_factor, warmup_steps, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparams = sum([p.numel() for p in model.parameters()])\n",
    "print('Model parameters: %d' % nparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Ready the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = batchify(corpus.train, batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Use random length sequences\n",
    "    seq_lens = []\n",
    "    tot_len = 0\n",
    "    jitter = 0.15 * seq_len\n",
    "    while tot_len < train_data.size(0) - 2:\n",
    "        if train_data.size(0) - tot_len - 2 <= seq_len + jitter:\n",
    "            slen = train_data.size(0) - tot_len - 2\n",
    "        else:\n",
    "            slen = int(np.random.normal(seq_len, jitter))\n",
    "            if slen <= 0:\n",
    "                slen = seq_len    # eh\n",
    "            if tot_len + slen >= train_data.size(0) - jitter - 2:\n",
    "                slen = train_data.size(0) - tot_len - 2\n",
    "        seq_lens.append(slen)\n",
    "        tot_len += slen\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    # Initialize RNN states\n",
    "    states = model.init_states(batch_size)\n",
    "    # Prep metainfo\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch, i in enumerate(np.cumsum(seq_lens)):\n",
    "        # Get training data\n",
    "        data, targets = get_batch(train_data, i, seq_lens[batch])\n",
    "        # Repackage the hidden states\n",
    "        states = repackage_hidden(states)\n",
    "        # Zero out gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Run the model forward\n",
    "        output, states = model(data, states)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        # Propagate loss gradient backwards\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        # Scale the batch learning rate so that shorter sequences aren't \"stronger\"\n",
    "        scaled_lr = [\n",
    "            r*seq_lens[batch] / seq_len for r in lr_scheduler.get_lr()\n",
    "        ]\n",
    "        for param_group, r in zip(optimizer.param_groups, scaled_lr):\n",
    "            param_group['lr'] = r\n",
    "        # Adjust parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get some metainfo\n",
    "        total_loss += loss.data\n",
    "        lr = np.mean(scaled_lr)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss[0] / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('{:5d}/{:5d} batches | {:5.2f} ms/batch | lr: {:0.4g} | loss: {:5.2f} | perplexity: {:8.2f}'.format(\n",
    "                batch, len(seq_lens), elapsed * 1000/log_interval, lr, cur_loss, np.exp(cur_loss)\n",
    "            ))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_src):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    states = model.init_states(eval_batch_size)\n",
    "    for i in range(0, data_src.size(0) - 1, seq_len):\n",
    "        # Get data\n",
    "        data, targets = get_batch(data_src, i, seq_len, evaluate = True)\n",
    "        # Repackage the hidden states\n",
    "        states = repackage_hidden(states)\n",
    "        # Evaluate\n",
    "        output, states = model(data, states)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        total_loss += len(data) * loss.data\n",
    "    return total_loss[0] / len(data_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1) lr = 5.379e-05\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1145.74 ms/batch | lr: 6.276e-05 | loss:  9.00 | perplexity:  8080.81\n",
      "  200/  717 batches | 1065.42 ms/batch | lr: 4.483e-05 | loss:  7.23 | perplexity:  1376.84\n",
      "  300/  717 batches | 1139.16 ms/batch | lr: 4.483e-05 | loss:  6.68 | perplexity:   794.16\n",
      "  400/  717 batches | 1171.78 ms/batch | lr: 3.885e-05 | loss:  6.61 | perplexity:   739.43\n",
      "  500/  717 batches | 1196.25 ms/batch | lr: 3.885e-05 | loss:  6.59 | perplexity:   728.44\n",
      "  600/  717 batches | 1243.73 ms/batch | lr: 4.781e-05 | loss:  6.58 | perplexity:   721.90\n",
      "  700/  717 batches | 1247.88 ms/batch | lr: 5.379e-05 | loss:  6.60 | perplexity:   734.10\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 839.87 s | valid_loss:  6.56 | valid_perplexity:   702.97\n",
      "=====================================================================================\n",
      "Epoch   2) lr = 0.0001076\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1491.21 ms/batch | lr: 0.0001375 | loss:  6.64 | perplexity:   761.47\n",
      "  200/  717 batches | 1157.12 ms/batch | lr: 0.0001016 | loss:  6.56 | perplexity:   702.80\n",
      "  300/  717 batches | 1293.22 ms/batch | lr: 0.0001255 | loss:  6.56 | perplexity:   705.15\n",
      "  400/  717 batches | 1194.73 ms/batch | lr: 0.0001375 | loss:  6.59 | perplexity:   728.09\n",
      "  500/  717 batches | 1327.58 ms/batch | lr: 0.0001195 | loss:  6.58 | perplexity:   720.90\n",
      "  600/  717 batches | 1292.69 ms/batch | lr: 9.563e-05 | loss:  6.57 | perplexity:   716.59\n",
      "  700/  717 batches | 1384.21 ms/batch | lr: 7.77e-05 | loss:  6.58 | perplexity:   722.22\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 938.44 s | valid_loss:  6.57 | valid_perplexity:   710.51\n",
      "=====================================================================================\n",
      "Epoch   3) lr = 0.0001614\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1192.83 ms/batch | lr: 0.0001434 | loss:  6.61 | perplexity:   743.53\n",
      "  200/  716 batches | 1160.84 ms/batch | lr: 0.0001703 | loss:  6.52 | perplexity:   679.70\n",
      "  300/  716 batches | 1186.48 ms/batch | lr: 0.0001703 | loss:  6.51 | perplexity:   670.71\n",
      "  400/  716 batches | 1120.30 ms/batch | lr: 0.0001434 | loss:  6.51 | perplexity:   671.94\n",
      "  500/  716 batches | 1183.23 ms/batch | lr: 0.0001793 | loss:  6.48 | perplexity:   653.40\n",
      "  600/  716 batches | 1188.24 ms/batch | lr: 0.0001165 | loss:  6.45 | perplexity:   633.28\n",
      "  700/  716 batches | 1175.85 ms/batch | lr: 0.0001614 | loss:  6.45 | perplexity:   630.71\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 835.76 s | valid_loss:  6.43 | valid_perplexity:   620.49\n",
      "=====================================================================================\n",
      "Epoch   4) lr = 0.0002152\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  725 batches | 1156.22 ms/batch | lr: 0.0002032 | loss:  6.47 | perplexity:   644.30\n",
      "  200/  725 batches | 1109.79 ms/batch | lr: 0.0002271 | loss:  6.37 | perplexity:   583.85\n",
      "  300/  725 batches | 1158.49 ms/batch | lr: 0.0002032 | loss:  6.36 | perplexity:   578.02\n",
      "  400/  725 batches | 1266.07 ms/batch | lr: 0.0002391 | loss:  6.37 | perplexity:   583.92\n",
      "  500/  725 batches | 1189.98 ms/batch | lr: 0.0001554 | loss:  6.35 | perplexity:   572.61\n",
      "  600/  725 batches | 1157.75 ms/batch | lr: 0.0001913 | loss:  6.33 | perplexity:   561.40\n",
      "  700/  725 batches | 1144.78 ms/batch | lr: 0.0002152 | loss:  6.32 | perplexity:   557.56\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 841.96 s | valid_loss:  6.31 | valid_perplexity:   551.06\n",
      "=====================================================================================\n",
      "Epoch   5) lr = 0.000269\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1206.15 ms/batch | lr: 0.0002241 | loss:  6.34 | perplexity:   566.72\n",
      "  200/  718 batches | 1130.22 ms/batch | lr: 0.0002839 | loss:  6.24 | perplexity:   512.12\n",
      "  300/  718 batches | 1110.22 ms/batch | lr: 0.0002988 | loss:  6.22 | perplexity:   500.21\n",
      "  400/  718 batches | 1111.88 ms/batch | lr: 0.0001942 | loss:  6.24 | perplexity:   511.52\n",
      "  500/  718 batches | 1109.99 ms/batch | lr: 0.0003138 | loss:  6.20 | perplexity:   493.23\n",
      "  600/  718 batches | 1143.63 ms/batch | lr: 0.000269 | loss:  6.17 | perplexity:   476.26\n",
      "  700/  718 batches | 1103.30 ms/batch | lr: 0.0002391 | loss:  6.18 | perplexity:   481.13\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 809.81 s | valid_loss:  6.15 | valid_perplexity:   470.81\n",
      "=====================================================================================\n",
      "Epoch   6) lr = 0.0003227\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  724 batches | 1134.85 ms/batch | lr: 0.0003048 | loss:  6.19 | perplexity:   486.06\n",
      "  200/  724 batches | 1093.02 ms/batch | lr: 0.0003227 | loss:  6.07 | perplexity:   433.92\n",
      "  300/  724 batches | 1104.12 ms/batch | lr: 0.0003765 | loss:  6.06 | perplexity:   428.64\n",
      "  400/  724 batches | 1108.69 ms/batch | lr: 0.0003407 | loss:  6.08 | perplexity:   437.90\n",
      "  500/  724 batches | 1101.94 ms/batch | lr: 0.0003765 | loss:  6.05 | perplexity:   425.52\n",
      "  600/  724 batches | 1089.96 ms/batch | lr: 0.000269 | loss:  6.01 | perplexity:   408.73\n",
      "  700/  724 batches | 1051.43 ms/batch | lr: 0.000251 | loss:  6.00 | perplexity:   405.29\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 790.04 s | valid_loss:  5.99 | valid_perplexity:   397.63\n",
      "=====================================================================================\n",
      "Epoch   7) lr = 0.0003765\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1097.01 ms/batch | lr: 0.0004184 | loss:  6.02 | perplexity:   411.90\n",
      "  200/  717 batches | 1141.65 ms/batch | lr: 0.0002929 | loss:  5.90 | perplexity:   365.24\n",
      "  300/  717 batches | 1100.50 ms/batch | lr: 0.0003347 | loss:  5.88 | perplexity:   358.16\n",
      "  400/  717 batches | 1077.90 ms/batch | lr: 0.0003765 | loss:  5.89 | perplexity:   363.02\n",
      "  500/  717 batches | 1078.39 ms/batch | lr: 0.0003975 | loss:  5.85 | perplexity:   348.65\n",
      "  600/  717 batches | 1113.79 ms/batch | lr: 0.0003975 | loss:  5.85 | perplexity:   347.09\n",
      "  700/  717 batches | 1122.99 ms/batch | lr: 0.0003556 | loss:  5.83 | perplexity:   339.95\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 789.17 s | valid_loss:  5.82 | valid_perplexity:   336.16\n",
      "=====================================================================================\n",
      "Epoch   8) lr = 0.0004303\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1078.04 ms/batch | lr: 0.0004064 | loss:  5.83 | perplexity:   341.36\n",
      "  200/  719 batches | 1115.24 ms/batch | lr: 0.0004781 | loss:  5.73 | perplexity:   308.03\n",
      "  300/  719 batches | 1100.60 ms/batch | lr: 0.0005021 | loss:  5.69 | perplexity:   295.54\n",
      "  400/  719 batches | 1064.04 ms/batch | lr: 0.0004542 | loss:  5.72 | perplexity:   304.01\n",
      "  500/  719 batches | 1090.93 ms/batch | lr: 0.0004781 | loss:  5.67 | perplexity:   289.38\n",
      "  600/  719 batches | 1129.74 ms/batch | lr: 0.0004064 | loss:  5.67 | perplexity:   288.76\n",
      "  700/  719 batches | 1082.80 ms/batch | lr: 0.0003825 | loss:  5.66 | perplexity:   286.12\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 783.00 s | valid_loss:  5.66 | valid_perplexity:   288.49\n",
      "=====================================================================================\n",
      "Epoch   9) lr = 0.0004841\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1120.72 ms/batch | lr: 0.0004034 | loss:  5.66 | perplexity:   288.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200/  715 batches | 1093.49 ms/batch | lr: 0.0004303 | loss:  5.53 | perplexity:   252.82\n",
      "  300/  715 batches | 1082.68 ms/batch | lr: 0.0005648 | loss:  5.50 | perplexity:   245.03\n",
      "  400/  715 batches | 1153.28 ms/batch | lr: 0.0005379 | loss:  5.56 | perplexity:   259.93\n",
      "  500/  715 batches | 1072.52 ms/batch | lr: 0.0004034 | loss:  5.49 | perplexity:   243.29\n",
      "  600/  715 batches | 1097.76 ms/batch | lr: 0.0004841 | loss:  5.47 | perplexity:   238.49\n",
      "  700/  715 batches | 1101.78 ms/batch | lr: 0.0003496 | loss:  5.46 | perplexity:   234.74\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 784.66 s | valid_loss:  5.52 | valid_perplexity:   250.65\n",
      "=====================================================================================\n",
      "Epoch  10) lr = 0.0005379\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1095.47 ms/batch | lr: 0.0003885 | loss:  5.48 | perplexity:   240.25\n",
      "  200/  719 batches | 1143.27 ms/batch | lr: 0.0006575 | loss:  5.37 | perplexity:   214.73\n",
      "  300/  719 batches | 1100.61 ms/batch | lr: 0.0004483 | loss:  5.33 | perplexity:   207.10\n",
      "  400/  719 batches | 1077.01 ms/batch | lr: 0.0004781 | loss:  5.36 | perplexity:   212.98\n",
      "  500/  719 batches | 1084.56 ms/batch | lr: 0.0006575 | loss:  5.34 | perplexity:   209.09\n",
      "  600/  719 batches | 1087.56 ms/batch | lr: 0.000508 | loss:  5.29 | perplexity:   199.12\n",
      "  700/  719 batches | 1114.07 ms/batch | lr: 0.0003287 | loss:  5.29 | perplexity:   198.43\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 787.58 s | valid_loss:  5.35 | valid_perplexity:   209.85\n",
      "=====================================================================================\n",
      "Epoch  11) lr = 0.0005917\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1114.85 ms/batch | lr: 0.0004602 | loss:  5.30 | perplexity:   199.96\n",
      "  200/  715 batches | 1077.15 ms/batch | lr: 0.0005588 | loss:  5.19 | perplexity:   180.33\n",
      "  300/  715 batches | 1099.69 ms/batch | lr: 0.000526 | loss:  5.16 | perplexity:   173.44\n",
      "  400/  715 batches | 1103.45 ms/batch | lr: 0.0003945 | loss:  5.21 | perplexity:   183.57\n",
      "  500/  715 batches | 1089.60 ms/batch | lr: 0.0007232 | loss:  5.12 | perplexity:   167.81\n",
      "  600/  715 batches | 1121.83 ms/batch | lr: 0.000526 | loss:  5.15 | perplexity:   171.85\n",
      "  700/  715 batches | 1104.57 ms/batch | lr: 0.0006246 | loss:  5.12 | perplexity:   167.40\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 785.50 s | valid_loss:  5.23 | valid_perplexity:   186.84\n",
      "=====================================================================================\n",
      "Epoch  12) lr = 0.0006455\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1104.98 ms/batch | lr: 0.0004662 | loss:  5.12 | perplexity:   168.03\n",
      "  200/  721 batches | 1052.32 ms/batch | lr: 0.0006096 | loss:  4.96 | perplexity:   142.64\n",
      "  300/  721 batches | 1149.94 ms/batch | lr: 0.0004303 | loss:  5.02 | perplexity:   150.73\n",
      "  400/  721 batches | 1072.84 ms/batch | lr: 0.0006814 | loss:  5.01 | perplexity:   149.53\n",
      "  500/  721 batches | 1091.60 ms/batch | lr: 0.0006814 | loss:  4.99 | perplexity:   146.43\n",
      "  600/  721 batches | 1085.08 ms/batch | lr: 0.0007172 | loss:  4.95 | perplexity:   141.02\n",
      "  700/  721 batches | 1108.87 ms/batch | lr: 0.0006096 | loss:  4.95 | perplexity:   141.72\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 787.58 s | valid_loss:  5.08 | valid_perplexity:   160.65\n",
      "=====================================================================================\n",
      "Epoch  13) lr = 0.0006993\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1143.37 ms/batch | lr: 0.000505 | loss:  4.97 | perplexity:   143.88\n",
      "  200/  716 batches | 1104.80 ms/batch | lr: 0.0005827 | loss:  4.88 | perplexity:   131.02\n",
      "  300/  716 batches | 1090.30 ms/batch | lr: 0.0008158 | loss:  4.82 | perplexity:   123.56\n",
      "  400/  716 batches | 1133.39 ms/batch | lr: 0.0006604 | loss:  4.88 | perplexity:   131.58\n",
      "  500/  716 batches | 1132.34 ms/batch | lr: 0.0006604 | loss:  4.82 | perplexity:   123.64\n",
      "  600/  716 batches | 1143.52 ms/batch | lr: 0.0006993 | loss:  4.83 | perplexity:   125.35\n",
      "  700/  716 batches | 1134.22 ms/batch | lr: 0.0006604 | loss:  4.79 | perplexity:   120.02\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 804.13 s | valid_loss:  4.97 | valid_perplexity:   144.30\n",
      "=====================================================================================\n",
      "Epoch  14) lr = 0.0007531\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1111.50 ms/batch | lr: 0.0006694 | loss:  4.80 | perplexity:   121.60\n",
      "  200/  715 batches | 1124.09 ms/batch | lr: 0.0008786 | loss:  4.72 | perplexity:   111.93\n",
      "  300/  715 batches | 1121.59 ms/batch | lr: 0.0008368 | loss:  4.68 | perplexity:   108.01\n",
      "  400/  715 batches | 1110.95 ms/batch | lr: 0.0007949 | loss:  4.70 | perplexity:   109.78\n",
      "  500/  715 batches | 1134.73 ms/batch | lr: 0.0007112 | loss:  4.68 | perplexity:   107.26\n",
      "  600/  715 batches | 1102.78 ms/batch | lr: 0.0007112 | loss:  4.65 | perplexity:   104.59\n",
      "  700/  715 batches | 1102.53 ms/batch | lr: 0.0007112 | loss:  4.66 | perplexity:   105.37\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 796.33 s | valid_loss:  4.73 | valid_perplexity:   112.81\n",
      "=====================================================================================\n",
      "Epoch  15) lr = 0.0008069\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1111.58 ms/batch | lr: 0.000762 | loss:  4.67 | perplexity:   106.34\n",
      "  200/  719 batches | 1097.58 ms/batch | lr: 0.0007172 | loss:  4.56 | perplexity:    95.66\n",
      "  300/  719 batches | 1094.34 ms/batch | lr: 0.0008069 | loss:  4.50 | perplexity:    90.25\n",
      "  400/  719 batches | 1077.69 ms/batch | lr: 0.0007172 | loss:  4.52 | perplexity:    92.02\n",
      "  500/  719 batches | 1107.48 ms/batch | lr: 0.0008069 | loss:  4.54 | perplexity:    93.85\n",
      "  600/  719 batches | 1082.19 ms/batch | lr: 0.0007172 | loss:  4.50 | perplexity:    89.84\n",
      "  700/  719 batches | 1110.37 ms/batch | lr: 0.000762 | loss:  4.51 | perplexity:    90.63\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 787.44 s | valid_loss:  4.62 | valid_perplexity:   101.66\n",
      "=====================================================================================\n",
      "Epoch  16) lr = 0.0007813\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1135.55 ms/batch | lr: 0.0007378 | loss:  4.52 | perplexity:    92.08\n",
      "  200/  718 batches | 1069.86 ms/batch | lr: 0.0009115 | loss:  4.36 | perplexity:    78.11\n",
      "  300/  718 batches | 1093.39 ms/batch | lr: 0.0007378 | loss:  4.35 | perplexity:    77.32\n",
      "  400/  718 batches | 1108.08 ms/batch | lr: 0.0009549 | loss:  4.39 | perplexity:    80.74\n",
      "  500/  718 batches | 1125.93 ms/batch | lr: 0.0007378 | loss:  4.41 | perplexity:    82.52\n",
      "  600/  718 batches | 1135.87 ms/batch | lr: 0.000651 | loss:  4.34 | perplexity:    76.63\n",
      "  700/  718 batches | 1100.20 ms/batch | lr: 0.0008247 | loss:  4.33 | perplexity:    76.21\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 795.16 s | valid_loss:  4.47 | valid_perplexity:    87.53\n",
      "=====================================================================================\n",
      "Epoch  17) lr = 0.0007579\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1145.64 ms/batch | lr: 0.0006737 | loss:  4.32 | perplexity:    75.15\n",
      "  200/  721 batches | 1135.40 ms/batch | lr: 0.0007579 | loss:  4.22 | perplexity:    67.74\n",
      "  300/  721 batches | 1124.55 ms/batch | lr: 0.0006737 | loss:  4.18 | perplexity:    65.09\n",
      "  400/  721 batches | 1195.64 ms/batch | lr: 0.0005895 | loss:  4.28 | perplexity:    72.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  500/  721 batches | 1119.26 ms/batch | lr: 0.0008421 | loss:  4.21 | perplexity:    67.66\n",
      "  600/  721 batches | 1130.68 ms/batch | lr: 0.0005895 | loss:  4.23 | perplexity:    68.75\n",
      "  700/  721 batches | 1114.32 ms/batch | lr: 0.0007158 | loss:  4.17 | perplexity:    64.72\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 817.36 s | valid_loss:  4.30 | valid_perplexity:    73.66\n",
      "=====================================================================================\n",
      "Epoch  18) lr = 0.0007366\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1173.02 ms/batch | lr: 0.0007366 | loss:  4.22 | perplexity:    67.84\n",
      "  200/  715 batches | 1165.18 ms/batch | lr: 0.000532 | loss:  4.08 | perplexity:    58.87\n",
      "  300/  715 batches | 1151.29 ms/batch | lr: 0.0006956 | loss:  4.07 | perplexity:    58.28\n",
      "  400/  715 batches | 1146.41 ms/batch | lr: 0.0009412 | loss:  4.11 | perplexity:    60.99\n",
      "  500/  715 batches | 1106.56 ms/batch | lr: 0.0008593 | loss:  4.07 | perplexity:    58.73\n",
      "  600/  715 batches | 1186.21 ms/batch | lr: 0.0007775 | loss:  4.13 | perplexity:    62.43\n",
      "  700/  715 batches | 1166.48 ms/batch | lr: 0.0009003 | loss:  4.07 | perplexity:    58.68\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 823.78 s | valid_loss:  4.17 | valid_perplexity:    64.43\n",
      "=====================================================================================\n",
      "Epoch  19) lr = 0.0007169\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  720 batches | 1134.83 ms/batch | lr: 0.0008364 | loss:  4.07 | perplexity:    58.77\n",
      "  200/  720 batches | 1087.58 ms/batch | lr: 0.0005974 | loss:  3.94 | perplexity:    51.58\n",
      "  300/  720 batches | 1125.30 ms/batch | lr: 0.0007568 | loss:  3.99 | perplexity:    54.07\n",
      "  400/  720 batches | 1128.60 ms/batch | lr: 0.0007966 | loss:  4.02 | perplexity:    55.43\n",
      "  500/  720 batches | 1136.49 ms/batch | lr: 0.0006373 | loss:  3.95 | perplexity:    51.88\n",
      "  600/  720 batches | 1121.95 ms/batch | lr: 0.0006771 | loss:  3.99 | perplexity:    54.08\n",
      "  700/  720 batches | 1111.56 ms/batch | lr: 0.0007966 | loss:  3.93 | perplexity:    50.80\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 804.49 s | valid_loss:  4.18 | valid_perplexity:    65.35\n",
      "=====================================================================================\n",
      "Epoch  20) lr = 0.0006988\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1134.42 ms/batch | lr: 0.0007764 | loss:  3.99 | perplexity:    54.30\n",
      "  200/  716 batches | 1108.99 ms/batch | lr: 0.0007764 | loss:  3.86 | perplexity:    47.52\n",
      "  300/  716 batches | 1161.29 ms/batch | lr: 0.0006988 | loss:  3.85 | perplexity:    47.07\n",
      "  400/  716 batches | 1102.65 ms/batch | lr: 0.0008541 | loss:  3.87 | perplexity:    48.01\n",
      "  500/  716 batches | 1103.38 ms/batch | lr: 0.0006988 | loss:  3.88 | perplexity:    48.64\n",
      "  600/  716 batches | 1104.26 ms/batch | lr: 0.0006211 | loss:  3.86 | perplexity:    47.44\n",
      "  700/  716 batches | 1126.31 ms/batch | lr: 0.0006211 | loss:  3.91 | perplexity:    49.67\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 799.92 s | valid_loss:  4.13 | valid_perplexity:    62.17\n",
      "=====================================================================================\n",
      "Epoch  21) lr = 0.0006819\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1184.76 ms/batch | lr: 0.0007956 | loss:  3.89 | perplexity:    49.12\n",
      "  200/  715 batches | 1118.41 ms/batch | lr: 0.0007956 | loss:  3.77 | perplexity:    43.53\n",
      "  300/  715 batches | 1111.62 ms/batch | lr: 0.000644 | loss:  3.76 | perplexity:    43.10\n",
      "  400/  715 batches | 1103.48 ms/batch | lr: 0.0007198 | loss:  3.81 | perplexity:    45.21\n",
      "  500/  715 batches | 1141.80 ms/batch | lr: 0.0006062 | loss:  3.82 | perplexity:    45.75\n",
      "  600/  715 batches | 1143.97 ms/batch | lr: 0.0007198 | loss:  3.78 | perplexity:    43.61\n",
      "  700/  715 batches | 1100.65 ms/batch | lr: 0.0008335 | loss:  3.76 | perplexity:    42.93\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 805.46 s | valid_loss:  3.92 | valid_perplexity:    50.49\n",
      "=====================================================================================\n",
      "Epoch  22) lr = 0.0006663\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  720 batches | 1120.97 ms/batch | lr: 0.0006292 | loss:  3.78 | perplexity:    43.71\n",
      "  200/  720 batches | 1119.53 ms/batch | lr: 0.0005552 | loss:  3.70 | perplexity:    40.27\n",
      "  300/  720 batches | 1123.14 ms/batch | lr: 0.0008143 | loss:  3.69 | perplexity:    40.19\n",
      "  400/  720 batches | 1160.23 ms/batch | lr: 0.0005922 | loss:  3.71 | perplexity:    40.72\n",
      "  500/  720 batches | 1095.37 ms/batch | lr: 0.0005552 | loss:  3.71 | perplexity:    40.72\n",
      "  600/  720 batches | 1091.33 ms/batch | lr: 0.0006663 | loss:  3.64 | perplexity:    38.04\n",
      "  700/  720 batches | 1112.49 ms/batch | lr: 0.0005552 | loss:  3.70 | perplexity:    40.26\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 803.03 s | valid_loss:  3.79 | valid_perplexity:    44.15\n",
      "=====================================================================================\n",
      "Epoch  23) lr = 0.0006516\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1130.80 ms/batch | lr: 0.0005792 | loss:  3.68 | perplexity:    39.71\n",
      "  200/  721 batches | 1148.12 ms/batch | lr: 0.0006878 | loss:  3.62 | perplexity:    37.44\n",
      "  300/  721 batches | 1140.02 ms/batch | lr: 0.0005068 | loss:  3.60 | perplexity:    36.64\n",
      "  400/  721 batches | 1102.82 ms/batch | lr: 0.000543 | loss:  3.60 | perplexity:    36.74\n",
      "  500/  721 batches | 1112.37 ms/batch | lr: 0.0005792 | loss:  3.61 | perplexity:    37.00\n",
      "  600/  721 batches | 1122.19 ms/batch | lr: 0.000543 | loss:  3.60 | perplexity:    36.56\n",
      "  700/  721 batches | 1120.80 ms/batch | lr: 0.0006878 | loss:  3.63 | perplexity:    37.70\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 810.75 s | valid_loss:  3.78 | valid_perplexity:    43.76\n",
      "=====================================================================================\n",
      "Epoch  24) lr = 0.0006379\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1134.01 ms/batch | lr: 0.0007796 | loss:  3.62 | perplexity:    37.21\n",
      "  200/  716 batches | 1138.69 ms/batch | lr: 0.0006024 | loss:  3.54 | perplexity:    34.47\n",
      "  300/  716 batches | 1127.91 ms/batch | lr: 0.000567 | loss:  3.51 | perplexity:    33.59\n",
      "  400/  716 batches | 1142.03 ms/batch | lr: 0.000567 | loss:  3.60 | perplexity:    36.50\n",
      "  500/  716 batches | 1143.75 ms/batch | lr: 0.0006733 | loss:  3.55 | perplexity:    34.79\n",
      "  600/  716 batches | 1169.50 ms/batch | lr: 0.0006379 | loss:  3.57 | perplexity:    35.35\n",
      "  700/  716 batches | 1100.14 ms/batch | lr: 0.0006024 | loss:  3.51 | perplexity:    33.61\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 810.63 s | valid_loss:  3.83 | valid_perplexity:    45.93\n",
      "=====================================================================================\n",
      "Epoch  25) lr = 0.000625\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  726 batches | 1135.66 ms/batch | lr: 0.0005556 | loss:  3.58 | perplexity:    35.74\n",
      "  200/  726 batches | 1115.12 ms/batch | lr: 0.0007292 | loss:  3.44 | perplexity:    31.17\n",
      "  300/  726 batches | 1154.32 ms/batch | lr: 0.0005208 | loss:  3.45 | perplexity:    31.36\n",
      "  400/  726 batches | 1113.50 ms/batch | lr: 0.0007292 | loss:  3.44 | perplexity:    31.25\n",
      "  500/  726 batches | 1113.71 ms/batch | lr: 0.0006944 | loss:  3.46 | perplexity:    31.92\n",
      "  600/  726 batches | 1112.59 ms/batch | lr: 0.0005556 | loss:  3.45 | perplexity:    31.35\n",
      "  700/  726 batches | 1107.36 ms/batch | lr: 0.0006597 | loss:  3.44 | perplexity:    31.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 811.50 s | valid_loss:  3.76 | valid_perplexity:    43.11\n",
      "=====================================================================================\n",
      "Epoch  26) lr = 0.0006129\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  724 batches | 1190.18 ms/batch | lr: 0.000715 | loss:  3.51 | perplexity:    33.57\n",
      "  200/  724 batches | 1129.95 ms/batch | lr: 0.000681 | loss:  3.41 | perplexity:    30.27\n",
      "  300/  724 batches | 1099.80 ms/batch | lr: 0.000681 | loss:  3.32 | perplexity:    27.70\n",
      "  400/  724 batches | 1128.53 ms/batch | lr: 0.0008172 | loss:  3.40 | perplexity:    29.88\n",
      "  500/  724 batches | 1102.93 ms/batch | lr: 0.0005788 | loss:  3.39 | perplexity:    29.73\n",
      "  600/  724 batches | 1138.62 ms/batch | lr: 0.0004767 | loss:  3.41 | perplexity:    30.40\n",
      "  700/  724 batches | 1135.53 ms/batch | lr: 0.0006129 | loss:  3.38 | perplexity:    29.45\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 817.94 s | valid_loss:  3.67 | valid_perplexity:    39.25\n",
      "=====================================================================================\n",
      "Epoch  27) lr = 0.0006014\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1158.77 ms/batch | lr: 0.000568 | loss:  3.44 | perplexity:    31.18\n",
      "  200/  721 batches | 1122.29 ms/batch | lr: 0.0006682 | loss:  3.30 | perplexity:    26.98\n",
      "  300/  721 batches | 1124.04 ms/batch | lr: 0.0006682 | loss:  3.30 | perplexity:    27.16\n",
      "  400/  721 batches | 1138.44 ms/batch | lr: 0.0006014 | loss:  3.33 | perplexity:    28.05\n",
      "  500/  721 batches | 1117.62 ms/batch | lr: 0.0006682 | loss:  3.36 | perplexity:    28.73\n",
      "  600/  721 batches | 1109.22 ms/batch | lr: 0.0006348 | loss:  3.32 | perplexity:    27.54\n",
      "  700/  721 batches | 1187.09 ms/batch | lr: 0.0006014 | loss:  3.39 | perplexity:    29.58\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 817.51 s | valid_loss:  3.55 | valid_perplexity:    34.80\n",
      "=====================================================================================\n",
      "Epoch  28) lr = 0.0005906\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  723 batches | 1151.17 ms/batch | lr: 0.0004921 | loss:  3.41 | perplexity:    30.25\n",
      "  200/  723 batches | 1148.41 ms/batch | lr: 0.000525 | loss:  3.25 | perplexity:    25.71\n",
      "  300/  723 batches | 1098.74 ms/batch | lr: 0.000525 | loss:  3.22 | perplexity:    24.94\n",
      "  400/  723 batches | 1145.35 ms/batch | lr: 0.000689 | loss:  3.31 | perplexity:    27.47\n",
      "  500/  723 batches | 1143.96 ms/batch | lr: 0.0007874 | loss:  3.30 | perplexity:    27.19\n",
      "  600/  723 batches | 1117.21 ms/batch | lr: 0.000525 | loss:  3.28 | perplexity:    26.51\n",
      "  700/  723 batches | 1165.81 ms/batch | lr: 0.000525 | loss:  3.29 | perplexity:    26.76\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 823.78 s | valid_loss:  3.76 | valid_perplexity:    42.74\n",
      "=====================================================================================\n",
      "Epoch  29) lr = 0.0005803\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  722 batches | 1129.27 ms/batch | lr: 0.0005158 | loss:  3.29 | perplexity:    26.73\n",
      "  200/  722 batches | 1167.86 ms/batch | lr: 0.0006448 | loss:  3.21 | perplexity:    24.83\n",
      "  300/  722 batches | 1123.27 ms/batch | lr: 0.0006448 | loss:  3.18 | perplexity:    24.16\n",
      "  400/  722 batches | 1169.14 ms/batch | lr: 0.000677 | loss:  3.27 | perplexity:    26.33\n",
      "  500/  722 batches | 1150.31 ms/batch | lr: 0.0005158 | loss:  3.19 | perplexity:    24.35\n",
      "  600/  722 batches | 1144.48 ms/batch | lr: 0.0006448 | loss:  3.21 | perplexity:    24.73\n",
      "  700/  722 batches | 1136.36 ms/batch | lr: 0.0005803 | loss:  3.20 | perplexity:    24.65\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 824.15 s | valid_loss:  3.43 | valid_perplexity:    30.96\n",
      "=====================================================================================\n",
      "Epoch  30) lr = 0.0005705\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1185.27 ms/batch | lr: 0.0007607 | loss:  3.27 | perplexity:    26.43\n",
      "  200/  715 batches | 1138.61 ms/batch | lr: 0.0005388 | loss:  3.14 | perplexity:    23.09\n",
      "  300/  715 batches | 1220.48 ms/batch | lr: 0.0005388 | loss:  3.20 | perplexity:    24.54\n",
      "  400/  715 batches | 1146.67 ms/batch | lr: 0.0005388 | loss:  3.28 | perplexity:    26.46\n",
      "  500/  715 batches | 1148.89 ms/batch | lr: 0.0005388 | loss:  3.22 | perplexity:    24.91\n",
      "  600/  715 batches | 1126.65 ms/batch | lr: 0.0005072 | loss:  3.13 | perplexity:    22.87\n",
      "  700/  715 batches | 1158.84 ms/batch | lr: 0.0004438 | loss:  3.25 | perplexity:    25.76\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 826.22 s | valid_loss:  3.49 | valid_perplexity:    32.73\n",
      "=====================================================================================\n",
      "Epoch  31) lr = 0.0005613\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1213.86 ms/batch | lr: 0.0006236 | loss:  3.23 | perplexity:    25.28\n",
      "  200/  718 batches | 1150.94 ms/batch | lr: 0.0006236 | loss:  3.10 | perplexity:    22.30\n",
      "  300/  718 batches | 1160.00 ms/batch | lr: 0.0005301 | loss:  3.10 | perplexity:    22.23\n",
      "  400/  718 batches | 1140.60 ms/batch | lr: 0.0004989 | loss:  3.13 | perplexity:    22.78\n",
      "  500/  718 batches | 1124.24 ms/batch | lr: 0.0005301 | loss:  3.10 | perplexity:    22.12\n",
      "  600/  718 batches | 1197.83 ms/batch | lr: 0.0007484 | loss:  3.17 | perplexity:    23.91\n",
      "  700/  718 batches | 1150.54 ms/batch | lr: 0.0004989 | loss:  3.15 | perplexity:    23.42\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 832.59 s | valid_loss:  3.46 | valid_perplexity:    31.74\n",
      "=====================================================================================\n",
      "Epoch  32) lr = 0.0005524\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  724 batches | 1172.32 ms/batch | lr: 0.0004604 | loss:  3.21 | perplexity:    24.71\n",
      "  200/  724 batches | 1124.20 ms/batch | lr: 0.0003683 | loss:  3.05 | perplexity:    21.06\n",
      "  300/  724 batches | 1136.91 ms/batch | lr: 0.0005217 | loss:  3.04 | perplexity:    21.01\n",
      "  400/  724 batches | 1170.17 ms/batch | lr: 0.0005831 | loss:  3.09 | perplexity:    22.01\n",
      "  500/  724 batches | 1143.71 ms/batch | lr: 0.000491 | loss:  3.08 | perplexity:    21.72\n",
      "  600/  724 batches | 1180.46 ms/batch | lr: 0.0005217 | loss:  3.13 | perplexity:    22.97\n",
      "  700/  724 batches | 1142.95 ms/batch | lr: 0.0005217 | loss:  3.06 | perplexity:    21.30\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 830.44 s | valid_loss:  3.30 | valid_perplexity:    27.21\n",
      "=====================================================================================\n",
      "Epoch  33) lr = 0.000544\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  713 batches | 1169.15 ms/batch | lr: 0.0004231 | loss:  3.10 | perplexity:    22.22\n",
      "  200/  713 batches | 1190.52 ms/batch | lr: 0.0006044 | loss:  3.02 | perplexity:    20.58\n",
      "  300/  713 batches | 1173.45 ms/batch | lr: 0.0005742 | loss:  3.03 | perplexity:    20.78\n",
      "  400/  713 batches | 1141.98 ms/batch | lr: 0.0003929 | loss:  3.03 | perplexity:    20.62\n",
      "  500/  713 batches | 1163.72 ms/batch | lr: 0.0006347 | loss:  3.06 | perplexity:    21.26\n",
      "  600/  713 batches | 1197.06 ms/batch | lr: 0.0006649 | loss:  3.07 | perplexity:    21.47\n",
      "  700/  713 batches | 1228.76 ms/batch | lr: 0.0006044 | loss:  3.07 | perplexity:    21.48\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 839.13 s | valid_loss:  3.28 | valid_perplexity:    26.62\n",
      "=====================================================================================\n",
      "Epoch  34) lr = 0.0005359\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100/  721 batches | 1188.85 ms/batch | lr: 0.0005657 | loss:  3.08 | perplexity:    21.83\n",
      "  200/  721 batches | 1191.53 ms/batch | lr: 0.0005359 | loss:  3.00 | perplexity:    20.06\n",
      "  300/  721 batches | 1146.90 ms/batch | lr: 0.0006253 | loss:  2.94 | perplexity:    18.88\n",
      "  400/  721 batches | 1157.81 ms/batch | lr: 0.0005062 | loss:  3.01 | perplexity:    20.31\n",
      "  500/  721 batches | 1186.28 ms/batch | lr: 0.0005359 | loss:  3.00 | perplexity:    20.17\n",
      "  600/  721 batches | 1133.31 ms/batch | lr: 0.000655 | loss:  2.98 | perplexity:    19.64\n",
      "  700/  721 batches | 1155.73 ms/batch | lr: 0.0005062 | loss:  3.01 | perplexity:    20.33\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 837.49 s | valid_loss:  3.26 | valid_perplexity:    25.99\n",
      "=====================================================================================\n",
      "Epoch  35) lr = 0.0005282\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1198.11 ms/batch | lr: 0.0004989 | loss:  3.05 | perplexity:    21.15\n",
      "  200/  719 batches | 1218.06 ms/batch | lr: 0.0006749 | loss:  2.94 | perplexity:    18.97\n",
      "  300/  719 batches | 1129.38 ms/batch | lr: 0.0004989 | loss:  2.89 | perplexity:    18.08\n",
      "  400/  719 batches | 1172.93 ms/batch | lr: 0.0004402 | loss:  3.03 | perplexity:    20.72\n",
      "  500/  719 batches | 1161.84 ms/batch | lr: 0.0004402 | loss:  2.97 | perplexity:    19.58\n",
      "  600/  719 batches | 1176.55 ms/batch | lr: 0.0005576 | loss:  3.01 | perplexity:    20.31\n",
      "  700/  719 batches | 1175.08 ms/batch | lr: 0.0003815 | loss:  2.97 | perplexity:    19.50\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 843.17 s | valid_loss:  3.17 | valid_perplexity:    23.76\n",
      "=====================================================================================\n",
      "Epoch  36) lr = 0.0005208\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1172.71 ms/batch | lr: 0.0005498 | loss:  3.00 | perplexity:    20.01\n",
      "  200/  718 batches | 1183.06 ms/batch | lr: 0.0003183 | loss:  2.93 | perplexity:    18.78\n",
      "  300/  718 batches | 1153.76 ms/batch | lr: 0.000463 | loss:  2.91 | perplexity:    18.29\n",
      "  400/  718 batches | 1168.50 ms/batch | lr: 0.0004919 | loss:  2.92 | perplexity:    18.58\n",
      "  500/  718 batches | 1221.06 ms/batch | lr: 0.0006076 | loss:  2.94 | perplexity:    18.94\n",
      "  600/  718 batches | 1155.92 ms/batch | lr: 0.0005787 | loss:  2.97 | perplexity:    19.43\n",
      "  700/  718 batches | 1203.86 ms/batch | lr: 0.0004919 | loss:  2.95 | perplexity:    19.20\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 843.55 s | valid_loss:  3.18 | valid_perplexity:    24.02\n",
      "=====================================================================================\n",
      "Epoch  37) lr = 0.0005137\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1194.89 ms/batch | lr: 0.000371 | loss:  2.95 | perplexity:    19.12\n",
      "  200/  719 batches | 1156.58 ms/batch | lr: 0.000371 | loss:  2.86 | perplexity:    17.53\n",
      "  300/  719 batches | 1206.98 ms/batch | lr: 0.0005137 | loss:  2.86 | perplexity:    17.38\n",
      "  400/  719 batches | 1172.42 ms/batch | lr: 0.0005423 | loss:  2.90 | perplexity:    18.09\n",
      "  500/  719 batches | 1186.04 ms/batch | lr: 0.0005423 | loss:  2.92 | perplexity:    18.48\n",
      "  600/  719 batches | 1185.96 ms/batch | lr: 0.0005708 | loss:  2.93 | perplexity:    18.66\n",
      "  700/  719 batches | 1152.61 ms/batch | lr: 0.0004567 | loss:  2.86 | perplexity:    17.46\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 845.63 s | valid_loss:  3.13 | valid_perplexity:    22.96\n",
      "=====================================================================================\n",
      "Epoch  38) lr = 0.0005069\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1238.43 ms/batch | lr: 0.0005351 | loss:  2.92 | perplexity:    18.50\n",
      "  200/  719 batches | 1174.96 ms/batch | lr: 0.0005351 | loss:  2.81 | perplexity:    16.53\n",
      "  300/  719 batches | 1191.36 ms/batch | lr: 0.0006759 | loss:  2.85 | perplexity:    17.24\n",
      "  400/  719 batches | 1133.07 ms/batch | lr: 0.0005914 | loss:  2.86 | perplexity:    17.44\n",
      "  500/  719 batches | 1177.41 ms/batch | lr: 0.0005351 | loss:  2.85 | perplexity:    17.36\n",
      "  600/  719 batches | 1214.85 ms/batch | lr: 0.0004506 | loss:  2.86 | perplexity:    17.50\n",
      "  700/  719 batches | 1203.09 ms/batch | lr: 0.0004506 | loss:  2.85 | perplexity:    17.33\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 855.13 s | valid_loss:  3.13 | valid_perplexity:    22.86\n",
      "=====================================================================================\n",
      "Epoch  39) lr = 0.0005004\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1204.23 ms/batch | lr: 0.0004726 | loss:  2.90 | perplexity:    18.13\n",
      "  200/  715 batches | 1207.78 ms/batch | lr: 0.0005838 | loss:  2.84 | perplexity:    17.12\n",
      "  300/  715 batches | 1169.70 ms/batch | lr: 0.0004726 | loss:  2.77 | perplexity:    15.99\n",
      "  400/  715 batches | 1189.64 ms/batch | lr: 0.0005282 | loss:  2.82 | perplexity:    16.74\n",
      "  500/  715 batches | 1195.66 ms/batch | lr: 0.000695 | loss:  2.88 | perplexity:    17.73\n",
      "  600/  715 batches | 1175.54 ms/batch | lr: 0.0005838 | loss:  2.81 | perplexity:    16.69\n",
      "  700/  715 batches | 1159.54 ms/batch | lr: 0.0005838 | loss:  2.79 | perplexity:    16.24\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 845.31 s | valid_loss:  3.19 | valid_perplexity:    24.32\n",
      "=====================================================================================\n",
      "Epoch  40) lr = 0.0004941\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1233.63 ms/batch | lr: 0.0004392 | loss:  2.88 | perplexity:    17.80\n",
      "  200/  718 batches | 1197.92 ms/batch | lr: 0.0004667 | loss:  2.79 | perplexity:    16.21\n",
      "  300/  718 batches | 1171.97 ms/batch | lr: 0.0004118 | loss:  2.73 | perplexity:    15.37\n",
      "  400/  718 batches | 1154.78 ms/batch | lr: 0.0004941 | loss:  2.80 | perplexity:    16.39\n",
      "  500/  718 batches | 1180.44 ms/batch | lr: 0.0004118 | loss:  2.77 | perplexity:    16.01\n",
      "  600/  718 batches | 1211.93 ms/batch | lr: 0.0004667 | loss:  2.77 | perplexity:    15.93\n",
      "  700/  718 batches | 1184.06 ms/batch | lr: 0.0004941 | loss:  2.80 | perplexity:    16.50\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 851.49 s | valid_loss:  3.06 | valid_perplexity:    21.30\n",
      "=====================================================================================\n",
      "Epoch  41) lr = 0.000488\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1217.81 ms/batch | lr: 0.0003796 | loss:  2.85 | perplexity:    17.34\n",
      "  200/  717 batches | 1213.39 ms/batch | lr: 0.0004067 | loss:  2.76 | perplexity:    15.82\n",
      "  300/  717 batches | 1186.31 ms/batch | lr: 0.0005152 | loss:  2.72 | perplexity:    15.23\n",
      "  400/  717 batches | 1194.08 ms/batch | lr: 0.0004609 | loss:  2.79 | perplexity:    16.21\n",
      "  500/  717 batches | 1161.12 ms/batch | lr: 0.0003796 | loss:  2.73 | perplexity:    15.33\n",
      "  600/  717 batches | 1197.41 ms/batch | lr: 0.0005152 | loss:  2.77 | perplexity:    16.00\n",
      "  700/  717 batches | 1155.94 ms/batch | lr: 0.0005423 | loss:  2.72 | perplexity:    15.22\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 850.64 s | valid_loss:  2.97 | valid_perplexity:    19.51\n",
      "=====================================================================================\n",
      "Epoch  42) lr = 0.0004822\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  722 batches | 1234.35 ms/batch | lr: 0.0004554 | loss:  2.81 | perplexity:    16.60\n",
      "  200/  722 batches | 1189.92 ms/batch | lr: 0.0004822 | loss:  2.70 | perplexity:    14.87\n",
      "  300/  722 batches | 1153.29 ms/batch | lr: 0.0006965 | loss:  2.63 | perplexity:    13.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  400/  722 batches | 1164.34 ms/batch | lr: 0.0004554 | loss:  2.75 | perplexity:    15.66\n",
      "  500/  722 batches | 1171.73 ms/batch | lr: 0.0004018 | loss:  2.71 | perplexity:    14.98\n",
      "  600/  722 batches | 1226.10 ms/batch | lr: 0.0004286 | loss:  2.77 | perplexity:    15.89\n",
      "  700/  722 batches | 1181.90 ms/batch | lr: 0.000509 | loss:  2.71 | perplexity:    14.98\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 855.19 s | valid_loss:  2.96 | valid_perplexity:    19.39\n",
      "=====================================================================================\n",
      "Epoch  43) lr = 0.0004766\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1205.10 ms/batch | lr: 0.0003707 | loss:  2.74 | perplexity:    15.55\n",
      "  200/  716 batches | 1152.04 ms/batch | lr: 0.0004236 | loss:  2.60 | perplexity:    13.42\n",
      "  300/  716 batches | 1179.75 ms/batch | lr: 0.0005295 | loss:  2.65 | perplexity:    14.13\n",
      "  400/  716 batches | 1238.52 ms/batch | lr: 0.000503 | loss:  2.71 | perplexity:    14.98\n",
      "  500/  716 batches | 1207.58 ms/batch | lr: 0.0005825 | loss:  2.74 | perplexity:    15.53\n",
      "  600/  716 batches | 1178.82 ms/batch | lr: 0.0003707 | loss:  2.71 | perplexity:    15.05\n",
      "  700/  716 batches | 1208.36 ms/batch | lr: 0.0004236 | loss:  2.74 | perplexity:    15.42\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 852.90 s | valid_loss:  3.00 | valid_perplexity:    20.16\n",
      "=====================================================================================\n",
      "Epoch  44) lr = 0.0004711\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  728 batches | 1190.69 ms/batch | lr: 0.0003926 | loss:  2.72 | perplexity:    15.11\n",
      "  200/  728 batches | 1206.80 ms/batch | lr: 0.0003926 | loss:  2.63 | perplexity:    13.94\n",
      "  300/  728 batches | 1160.89 ms/batch | lr: 0.0004973 | loss:  2.60 | perplexity:    13.44\n",
      "  400/  728 batches | 1165.74 ms/batch | lr: 0.0003926 | loss:  2.65 | perplexity:    14.16\n",
      "  500/  728 batches | 1176.48 ms/batch | lr: 0.0004449 | loss:  2.68 | perplexity:    14.62\n",
      "  600/  728 batches | 1181.00 ms/batch | lr: 0.0004973 | loss:  2.67 | perplexity:    14.45\n",
      "  700/  728 batches | 1189.09 ms/batch | lr: 0.0003664 | loss:  2.62 | perplexity:    13.69\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 857.36 s | valid_loss:  2.87 | valid_perplexity:    17.62\n",
      "=====================================================================================\n",
      "Epoch  45) lr = 0.0004658\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1206.56 ms/batch | lr: 0.0005176 | loss:  2.66 | perplexity:    14.25\n",
      "  200/  719 batches | 1209.50 ms/batch | lr: 0.0003882 | loss:  2.59 | perplexity:    13.36\n",
      "  300/  719 batches | 1193.24 ms/batch | lr: 0.0002847 | loss:  2.58 | perplexity:    13.19\n",
      "  400/  719 batches | 1213.75 ms/batch | lr: 0.0004658 | loss:  2.65 | perplexity:    14.09\n",
      "  500/  719 batches | 1164.33 ms/batch | lr: 0.0004141 | loss:  2.63 | perplexity:    13.85\n",
      "  600/  719 batches | 1184.00 ms/batch | lr: 0.00044 | loss:  2.64 | perplexity:    13.95\n",
      "  700/  719 batches | 1203.74 ms/batch | lr: 0.00044 | loss:  2.63 | perplexity:    13.93\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 856.84 s | valid_loss:  3.04 | valid_perplexity:    20.98\n",
      "=====================================================================================\n",
      "Epoch  46) lr = 0.0004608\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1198.95 ms/batch | lr: 0.000384 | loss:  2.66 | perplexity:    14.29\n",
      "  200/  716 batches | 1229.62 ms/batch | lr: 0.000384 | loss:  2.55 | perplexity:    12.85\n",
      "  300/  716 batches | 1208.58 ms/batch | lr: 0.000512 | loss:  2.63 | perplexity:    13.92\n",
      "  400/  716 batches | 1190.54 ms/batch | lr: 0.0005375 | loss:  2.59 | perplexity:    13.37\n",
      "  500/  716 batches | 1189.64 ms/batch | lr: 0.0004864 | loss:  2.59 | perplexity:    13.36\n",
      "  600/  716 batches | 1180.00 ms/batch | lr: 0.0004864 | loss:  2.61 | perplexity:    13.57\n",
      "  700/  716 batches | 1209.18 ms/batch | lr: 0.0004608 | loss:  2.63 | perplexity:    13.84\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 857.99 s | valid_loss:  2.89 | valid_perplexity:    17.92\n",
      "=====================================================================================\n",
      "Epoch  47) lr = 0.0004558\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  725 batches | 1199.72 ms/batch | lr: 0.0005065 | loss:  2.62 | perplexity:    13.80\n",
      "  200/  725 batches | 1173.57 ms/batch | lr: 0.0004052 | loss:  2.55 | perplexity:    12.76\n",
      "  300/  725 batches | 1170.90 ms/batch | lr: 0.0004812 | loss:  2.58 | perplexity:    13.15\n",
      "  400/  725 batches | 1173.26 ms/batch | lr: 0.0005318 | loss:  2.55 | perplexity:    12.87\n",
      "  500/  725 batches | 1218.99 ms/batch | lr: 0.0004052 | loss:  2.61 | perplexity:    13.67\n",
      "  600/  725 batches | 1211.20 ms/batch | lr: 0.0004558 | loss:  2.61 | perplexity:    13.67\n",
      "  700/  725 batches | 1164.93 ms/batch | lr: 0.0004305 | loss:  2.55 | perplexity:    12.80\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 856.89 s | valid_loss:  2.85 | valid_perplexity:    17.36\n",
      "=====================================================================================\n",
      "Epoch  48) lr = 0.0004511\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  714 batches | 1225.34 ms/batch | lr: 0.0003258 | loss:  2.64 | perplexity:    13.99\n",
      "  200/  714 batches | 1209.86 ms/batch | lr: 0.0003508 | loss:  2.53 | perplexity:    12.55\n",
      "  300/  714 batches | 1209.76 ms/batch | lr: 0.0005262 | loss:  2.51 | perplexity:    12.33\n",
      "  400/  714 batches | 1206.29 ms/batch | lr: 0.0005513 | loss:  2.58 | perplexity:    13.15\n",
      "  500/  714 batches | 1204.39 ms/batch | lr: 0.0004009 | loss:  2.57 | perplexity:    13.02\n",
      "  600/  714 batches | 1172.31 ms/batch | lr: 0.0003007 | loss:  2.54 | perplexity:    12.62\n",
      "  700/  714 batches | 1211.12 ms/batch | lr: 0.000426 | loss:  2.56 | perplexity:    12.87\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 857.80 s | valid_loss:  2.81 | valid_perplexity:    16.64\n",
      "=====================================================================================\n",
      "Epoch  49) lr = 0.0004464\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1185.24 ms/batch | lr: 0.0003968 | loss:  2.56 | perplexity:    12.93\n",
      "  200/  719 batches | 1195.22 ms/batch | lr: 0.0003968 | loss:  2.50 | perplexity:    12.20\n",
      "  300/  719 batches | 1217.78 ms/batch | lr: 0.0004464 | loss:  2.50 | perplexity:    12.14\n",
      "  400/  719 batches | 1173.83 ms/batch | lr: 0.000372 | loss:  2.52 | perplexity:    12.37\n",
      "  500/  719 batches | 1228.82 ms/batch | lr: 0.000372 | loss:  2.56 | perplexity:    12.93\n",
      "  600/  719 batches | 1216.38 ms/batch | lr: 0.0003224 | loss:  2.54 | perplexity:    12.68\n",
      "  700/  719 batches | 1192.45 ms/batch | lr: 0.0002976 | loss:  2.52 | perplexity:    12.48\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 859.87 s | valid_loss:  2.81 | valid_perplexity:    16.69\n",
      "=====================================================================================\n",
      "Epoch  50) lr = 0.0004419\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1187.30 ms/batch | lr: 0.0003928 | loss:  2.52 | perplexity:    12.38\n",
      "  200/  719 batches | 1209.00 ms/batch | lr: 0.000491 | loss:  2.53 | perplexity:    12.58\n",
      "  300/  719 batches | 1214.94 ms/batch | lr: 0.0003928 | loss:  2.44 | perplexity:    11.48\n",
      "  400/  719 batches | 1202.03 ms/batch | lr: 0.0005156 | loss:  2.50 | perplexity:    12.16\n",
      "  500/  719 batches | 1204.57 ms/batch | lr: 0.000491 | loss:  2.51 | perplexity:    12.27\n",
      "  600/  719 batches | 1212.79 ms/batch | lr: 0.0003928 | loss:  2.52 | perplexity:    12.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  700/  719 batches | 1179.27 ms/batch | lr: 0.0005156 | loss:  2.52 | perplexity:    12.37\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 860.52 s | valid_loss:  2.94 | valid_perplexity:    18.91\n",
      "=====================================================================================\n",
      "Epoch  51) lr = 0.0004376\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1206.07 ms/batch | lr: 0.000389 | loss:  2.56 | perplexity:    12.92\n",
      "  200/  719 batches | 1207.62 ms/batch | lr: 0.0004862 | loss:  2.44 | perplexity:    11.42\n",
      "  300/  719 batches | 1173.81 ms/batch | lr: 0.0003647 | loss:  2.44 | perplexity:    11.43\n",
      "  400/  719 batches | 1204.68 ms/batch | lr: 0.0003403 | loss:  2.54 | perplexity:    12.65\n",
      "  500/  719 batches | 1232.26 ms/batch | lr: 0.0004619 | loss:  2.48 | perplexity:    11.94\n",
      "  600/  719 batches | 1213.18 ms/batch | lr: 0.0003647 | loss:  2.52 | perplexity:    12.40\n",
      "  700/  719 batches | 1187.84 ms/batch | lr: 0.0003647 | loss:  2.48 | perplexity:    11.92\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 862.17 s | valid_loss:  2.75 | valid_perplexity:    15.65\n",
      "=====================================================================================\n",
      "Epoch  52) lr = 0.0004334\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  722 batches | 1210.36 ms/batch | lr: 0.0003852 | loss:  2.52 | perplexity:    12.46\n",
      "  200/  722 batches | 1193.86 ms/batch | lr: 0.0004093 | loss:  2.40 | perplexity:    11.05\n",
      "  300/  722 batches | 1219.54 ms/batch | lr: 0.0003852 | loss:  2.42 | perplexity:    11.22\n",
      "  400/  722 batches | 1160.43 ms/batch | lr: 0.0003611 | loss:  2.42 | perplexity:    11.28\n",
      "  500/  722 batches | 1215.69 ms/batch | lr: 0.0004574 | loss:  2.46 | perplexity:    11.74\n",
      "  600/  722 batches | 1165.67 ms/batch | lr: 0.0003611 | loss:  2.44 | perplexity:    11.47\n",
      "  700/  722 batches | 1223.39 ms/batch | lr: 0.0004334 | loss:  2.49 | perplexity:    12.05\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 862.88 s | valid_loss:  2.69 | valid_perplexity:    14.69\n",
      "=====================================================================================\n",
      "Epoch  53) lr = 0.0004293\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1270.83 ms/batch | lr: 0.0003339 | loss:  2.52 | perplexity:    12.44\n",
      "  200/  717 batches | 1199.47 ms/batch | lr: 0.0004531 | loss:  2.39 | perplexity:    10.91\n",
      "  300/  717 batches | 1159.54 ms/batch | lr: 0.0003577 | loss:  2.36 | perplexity:    10.60\n",
      "  400/  717 batches | 1204.93 ms/batch | lr: 0.0004293 | loss:  2.44 | perplexity:    11.44\n",
      "  500/  717 batches | 1202.55 ms/batch | lr: 0.0004293 | loss:  2.42 | perplexity:    11.26\n",
      "  600/  717 batches | 1228.80 ms/batch | lr: 0.0005246 | loss:  2.45 | perplexity:    11.64\n",
      "  700/  717 batches | 1211.12 ms/batch | lr: 0.0003577 | loss:  2.47 | perplexity:    11.78\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 866.58 s | valid_loss:  2.70 | valid_perplexity:    14.86\n",
      "=====================================================================================\n",
      "Epoch  54) lr = 0.0004253\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1205.17 ms/batch | lr: 0.0004016 | loss:  2.47 | perplexity:    11.87\n",
      "  200/  719 batches | 1158.32 ms/batch | lr: 0.0003071 | loss:  2.37 | perplexity:    10.67\n",
      "  300/  719 batches | 1258.55 ms/batch | lr: 0.0004489 | loss:  2.42 | perplexity:    11.23\n",
      "  400/  719 batches | 1197.04 ms/batch | lr: 0.0003544 | loss:  2.38 | perplexity:    10.85\n",
      "  500/  719 batches | 1184.82 ms/batch | lr: 0.000378 | loss:  2.39 | perplexity:    10.96\n",
      "  600/  719 batches | 1225.76 ms/batch | lr: 0.0005198 | loss:  2.46 | perplexity:    11.69\n",
      "  700/  719 batches | 1189.14 ms/batch | lr: 0.0004725 | loss:  2.42 | perplexity:    11.24\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 863.75 s | valid_loss:  2.73 | valid_perplexity:    15.37\n",
      "=====================================================================================\n",
      "Epoch  55) lr = 0.0004214\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1237.46 ms/batch | lr: 0.0002341 | loss:  2.45 | perplexity:    11.58\n",
      "  200/  719 batches | 1203.90 ms/batch | lr: 0.0003511 | loss:  2.33 | perplexity:    10.26\n",
      "  300/  719 batches | 1241.29 ms/batch | lr: 0.0005384 | loss:  2.42 | perplexity:    11.24\n",
      "  400/  719 batches | 1195.27 ms/batch | lr: 0.0004448 | loss:  2.38 | perplexity:    10.81\n",
      "  500/  719 batches | 1205.55 ms/batch | lr: 0.0004448 | loss:  2.40 | perplexity:    11.08\n",
      "  600/  719 batches | 1204.72 ms/batch | lr: 0.0003511 | loss:  2.41 | perplexity:    11.15\n",
      "  700/  719 batches | 1172.94 ms/batch | lr: 0.0003746 | loss:  2.37 | perplexity:    10.67\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 865.92 s | valid_loss:  2.71 | valid_perplexity:    14.96\n",
      "=====================================================================================\n",
      "Epoch  56) lr = 0.0004176\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  723 batches | 1206.62 ms/batch | lr: 0.0004176 | loss:  2.43 | perplexity:    11.31\n",
      "  200/  723 batches | 1211.12 ms/batch | lr: 0.0004408 | loss:  2.33 | perplexity:    10.31\n",
      "  300/  723 batches | 1167.09 ms/batch | lr: 0.0003016 | loss:  2.29 | perplexity:     9.90\n",
      "  400/  723 batches | 1236.01 ms/batch | lr: 0.0005104 | loss:  2.39 | perplexity:    10.88\n",
      "  500/  723 batches | 1171.31 ms/batch | lr: 0.0004408 | loss:  2.39 | perplexity:    10.93\n",
      "  600/  723 batches | 1178.65 ms/batch | lr: 0.0002784 | loss:  2.38 | perplexity:    10.83\n",
      "  700/  723 batches | 1216.40 ms/batch | lr: 0.0004176 | loss:  2.39 | perplexity:    10.94\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 862.70 s | valid_loss:  2.71 | valid_perplexity:    15.04\n",
      "=====================================================================================\n",
      "Epoch  57) lr = 0.0004139\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  713 batches | 1243.86 ms/batch | lr: 0.0004599 | loss:  2.41 | perplexity:    11.11\n",
      "  200/  713 batches | 1217.67 ms/batch | lr: 0.0004139 | loss:  2.33 | perplexity:    10.28\n",
      "  300/  713 batches | 1211.16 ms/batch | lr: 0.0003909 | loss:  2.33 | perplexity:    10.23\n",
      "  400/  713 batches | 1234.10 ms/batch | lr: 0.0003679 | loss:  2.39 | perplexity:    10.92\n",
      "  500/  713 batches | 1192.70 ms/batch | lr: 0.0003219 | loss:  2.37 | perplexity:    10.71\n",
      "  600/  713 batches | 1225.68 ms/batch | lr: 0.0003219 | loss:  2.34 | perplexity:    10.35\n",
      "  700/  713 batches | 1222.58 ms/batch | lr: 0.0004139 | loss:  2.40 | perplexity:    11.07\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 869.70 s | valid_loss:  2.63 | valid_perplexity:    13.81\n",
      "=====================================================================================\n",
      "Epoch  58) lr = 0.0004103\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  720 batches | 1183.52 ms/batch | lr: 0.0002964 | loss:  2.35 | perplexity:    10.48\n",
      "  200/  720 batches | 1195.57 ms/batch | lr: 0.0002964 | loss:  2.29 | perplexity:     9.90\n",
      "  300/  720 batches | 1225.37 ms/batch | lr: 0.0004559 | loss:  2.32 | perplexity:    10.13\n",
      "  400/  720 batches | 1283.98 ms/batch | lr: 0.0004559 | loss:  2.41 | perplexity:    11.17\n",
      "  500/  720 batches | 1180.83 ms/batch | lr: 0.0003875 | loss:  2.31 | perplexity:    10.06\n",
      "  600/  720 batches | 1205.19 ms/batch | lr: 0.0003875 | loss:  2.34 | perplexity:    10.38\n",
      "  700/  720 batches | 1186.92 ms/batch | lr: 0.0004787 | loss:  2.31 | perplexity:    10.04\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 867.51 s | valid_loss:  2.66 | valid_perplexity:    14.31\n",
      "=====================================================================================\n",
      "Epoch  59) lr = 0.0004068\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100/  720 batches | 1215.79 ms/batch | lr: 0.0002938 | loss:  2.34 | perplexity:    10.37\n",
      "  200/  720 batches | 1271.92 ms/batch | lr: 0.0004068 | loss:  2.31 | perplexity:    10.11\n",
      "  300/  720 batches | 1172.87 ms/batch | lr: 0.0004294 | loss:  2.27 | perplexity:     9.64\n",
      "  400/  720 batches | 1232.96 ms/batch | lr: 0.0005425 | loss:  2.35 | perplexity:    10.44\n",
      "  500/  720 batches | 1206.08 ms/batch | lr: 0.000339 | loss:  2.32 | perplexity:    10.23\n",
      "  600/  720 batches | 1250.99 ms/batch | lr: 0.0004746 | loss:  2.34 | perplexity:    10.43\n",
      "  700/  720 batches | 1228.74 ms/batch | lr: 0.0002938 | loss:  2.34 | perplexity:    10.41\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 879.35 s | valid_loss:  2.86 | valid_perplexity:    17.43\n",
      "=====================================================================================\n",
      "Epoch  60) lr = 0.0004034\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1282.09 ms/batch | lr: 0.0004034 | loss:  2.38 | perplexity:    10.78\n",
      "  200/  719 batches | 1218.38 ms/batch | lr: 0.0004034 | loss:  2.25 | perplexity:     9.46\n",
      "  300/  719 batches | 1235.60 ms/batch | lr: 0.0003586 | loss:  2.26 | perplexity:     9.60\n",
      "  400/  719 batches | 1265.00 ms/batch | lr: 0.0005603 | loss:  2.35 | perplexity:    10.48\n",
      "  500/  719 batches | 1228.92 ms/batch | lr: 0.0003362 | loss:  2.30 | perplexity:     9.97\n",
      "  600/  719 batches | 1234.19 ms/batch | lr: 0.0003362 | loss:  2.30 | perplexity:     9.94\n",
      "  700/  719 batches | 1204.81 ms/batch | lr: 0.0003586 | loss:  2.28 | perplexity:     9.80\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 887.26 s | valid_loss:  2.58 | valid_perplexity:    13.13\n",
      "=====================================================================================\n",
      "Epoch  61) lr = 0.0004001\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1249.59 ms/batch | lr: 0.0003334 | loss:  2.30 | perplexity:    10.01\n",
      "  200/  721 batches | 1227.32 ms/batch | lr: 0.000289 | loss:  2.26 | perplexity:     9.55\n",
      "  300/  721 batches | 1209.42 ms/batch | lr: 0.0003779 | loss:  2.25 | perplexity:     9.49\n",
      "  400/  721 batches | 1206.74 ms/batch | lr: 0.0003112 | loss:  2.27 | perplexity:     9.67\n",
      "  500/  721 batches | 1258.50 ms/batch | lr: 0.0003557 | loss:  2.31 | perplexity:    10.11\n",
      "  600/  721 batches | 1321.80 ms/batch | lr: 0.0004446 | loss:  2.29 | perplexity:     9.90\n",
      "  700/  721 batches | 1337.16 ms/batch | lr: 0.0004223 | loss:  2.25 | perplexity:     9.52\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 905.93 s | valid_loss:  2.57 | valid_perplexity:    13.08\n",
      "=====================================================================================\n",
      "Epoch  62) lr = 0.0003969\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1273.93 ms/batch | lr: 0.0003087 | loss:  2.35 | perplexity:    10.45\n",
      "  200/  715 batches | 1242.56 ms/batch | lr: 0.0003528 | loss:  2.28 | perplexity:     9.75\n",
      "  300/  715 batches | 1254.98 ms/batch | lr: 0.000441 | loss:  2.23 | perplexity:     9.31\n",
      "  400/  715 batches | 1258.15 ms/batch | lr: 0.0005733 | loss:  2.27 | perplexity:     9.69\n",
      "  500/  715 batches | 1247.03 ms/batch | lr: 0.0003528 | loss:  2.30 | perplexity:    10.00\n",
      "  600/  715 batches | 1226.13 ms/batch | lr: 0.000441 | loss:  2.26 | perplexity:     9.60\n",
      "  700/  715 batches | 1227.07 ms/batch | lr: 0.000463 | loss:  2.29 | perplexity:     9.90\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 891.54 s | valid_loss:  2.58 | valid_perplexity:    13.14\n",
      "=====================================================================================\n",
      "Epoch  63) lr = 0.0003937\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1244.60 ms/batch | lr: 0.0003718 | loss:  2.30 | perplexity:     9.96\n",
      "  200/  721 batches | 1234.40 ms/batch | lr: 0.0003062 | loss:  2.25 | perplexity:     9.47\n",
      "  300/  721 batches | 1233.30 ms/batch | lr: 0.0003937 | loss:  2.25 | perplexity:     9.51\n",
      "  400/  721 batches | 1205.01 ms/batch | lr: 0.0004375 | loss:  2.23 | perplexity:     9.34\n",
      "  500/  721 batches | 1246.27 ms/batch | lr: 0.0003718 | loss:  2.25 | perplexity:     9.51\n",
      "  600/  721 batches | 1210.71 ms/batch | lr: 0.0004593 | loss:  2.23 | perplexity:     9.34\n",
      "  700/  721 batches | 1249.87 ms/batch | lr: 0.000525 | loss:  2.28 | perplexity:     9.75\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 885.54 s | valid_loss:  2.54 | valid_perplexity:    12.63\n",
      "=====================================================================================\n",
      "Epoch  64) lr = 0.0003906\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1250.38 ms/batch | lr: 0.0003255 | loss:  2.29 | perplexity:     9.85\n",
      "  200/  719 batches | 1230.82 ms/batch | lr: 0.0004123 | loss:  2.14 | perplexity:     8.54\n",
      "  300/  719 batches | 1276.04 ms/batch | lr: 0.0004774 | loss:  2.22 | perplexity:     9.19\n",
      "  400/  719 batches | 1213.23 ms/batch | lr: 0.0003906 | loss:  2.22 | perplexity:     9.20\n",
      "  500/  719 batches | 1239.08 ms/batch | lr: 0.0002821 | loss:  2.26 | perplexity:     9.57\n",
      "  600/  719 batches | 1261.44 ms/batch | lr: 0.0002604 | loss:  2.28 | perplexity:     9.74\n",
      "  700/  719 batches | 1255.28 ms/batch | lr: 0.0003689 | loss:  2.19 | perplexity:     8.97\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 893.79 s | valid_loss:  2.49 | valid_perplexity:    12.05\n",
      "=====================================================================================\n",
      "Epoch  65) lr = 0.0003876\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  723 batches | 1240.15 ms/batch | lr: 0.0003445 | loss:  2.27 | perplexity:     9.63\n",
      "  200/  723 batches | 1244.76 ms/batch | lr: 0.000323 | loss:  2.18 | perplexity:     8.86\n",
      "  300/  723 batches | 1237.22 ms/batch | lr: 0.0004522 | loss:  2.17 | perplexity:     8.76\n",
      "  400/  723 batches | 1228.42 ms/batch | lr: 0.0004737 | loss:  2.19 | perplexity:     8.90\n",
      "  500/  723 batches | 1280.90 ms/batch | lr: 0.000323 | loss:  2.21 | perplexity:     9.08\n",
      "  600/  723 batches | 1225.49 ms/batch | lr: 0.000323 | loss:  2.24 | perplexity:     9.39\n",
      "  700/  723 batches | 1236.06 ms/batch | lr: 0.0003876 | loss:  2.20 | perplexity:     9.01\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 895.38 s | valid_loss:  2.49 | valid_perplexity:    12.03\n",
      "=====================================================================================\n",
      "Epoch  66) lr = 0.0003847\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  720 batches | 1265.26 ms/batch | lr: 0.0003206 | loss:  2.19 | perplexity:     8.94\n",
      "  200/  720 batches | 1435.20 ms/batch | lr: 0.0004274 | loss:  2.18 | perplexity:     8.89\n",
      "  300/  720 batches | 1441.91 ms/batch | lr: 0.0002992 | loss:  2.18 | perplexity:     8.84\n",
      "  400/  720 batches | 1408.18 ms/batch | lr: 0.0004701 | loss:  2.19 | perplexity:     8.95\n",
      "  500/  720 batches | 1396.51 ms/batch | lr: 0.0002992 | loss:  2.21 | perplexity:     9.09\n",
      "  600/  720 batches | 1361.55 ms/batch | lr: 0.0003847 | loss:  2.18 | perplexity:     8.87\n",
      "  700/  720 batches | 1418.99 ms/batch | lr: 0.0003847 | loss:  2.23 | perplexity:     9.28\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 998.59 s | valid_loss:  2.48 | valid_perplexity:    11.93\n",
      "=====================================================================================\n",
      "Epoch  67) lr = 0.0003818\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  720 batches | 1443.79 ms/batch | lr: 0.000403 | loss:  2.26 | perplexity:     9.57\n",
      "  200/  720 batches | 1426.51 ms/batch | lr: 0.0004242 | loss:  2.17 | perplexity:     8.77\n",
      "  300/  720 batches | 1394.55 ms/batch | lr: 0.0002333 | loss:  2.10 | perplexity:     8.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  400/  720 batches | 1444.01 ms/batch | lr: 0.0002969 | loss:  2.19 | perplexity:     8.96\n",
      "  500/  720 batches | 1408.26 ms/batch | lr: 0.000403 | loss:  2.21 | perplexity:     9.09\n",
      "  600/  720 batches | 1389.57 ms/batch | lr: 0.0003606 | loss:  2.18 | perplexity:     8.87\n",
      "  700/  720 batches | 1394.14 ms/batch | lr: 0.000403 | loss:  2.16 | perplexity:     8.67\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 1014.27 s | valid_loss:  2.46 | valid_perplexity:    11.70\n",
      "=====================================================================================\n",
      "Epoch  68) lr = 0.000379\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1458.97 ms/batch | lr: 0.0004421 | loss:  2.21 | perplexity:     9.08\n",
      "  200/  719 batches | 1401.83 ms/batch | lr: 0.0003579 | loss:  2.12 | perplexity:     8.32\n",
      "  300/  719 batches | 1325.08 ms/batch | lr: 0.0002526 | loss:  2.09 | perplexity:     8.09\n",
      "  400/  719 batches | 1425.32 ms/batch | lr: 0.0003158 | loss:  2.18 | perplexity:     8.85\n",
      "  500/  719 batches | 1482.63 ms/batch | lr: 0.0004 | loss:  2.19 | perplexity:     8.90\n",
      "  600/  719 batches | 1460.58 ms/batch | lr: 0.0003579 | loss:  2.24 | perplexity:     9.44\n",
      "  700/  719 batches | 1372.60 ms/batch | lr: 0.0004211 | loss:  2.15 | perplexity:     8.57\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 1015.22 s | valid_loss:  2.47 | valid_perplexity:    11.77\n",
      "=====================================================================================\n",
      "Epoch  69) lr = 0.0003762\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1377.05 ms/batch | lr: 0.0003135 | loss:  2.19 | perplexity:     8.94\n",
      "  200/  718 batches | 1432.08 ms/batch | lr: 0.0004389 | loss:  2.13 | perplexity:     8.45\n",
      "  300/  718 batches | 1370.25 ms/batch | lr: 0.0004389 | loss:  2.11 | perplexity:     8.22\n",
      "  400/  718 batches | 1385.85 ms/batch | lr: 0.0004389 | loss:  2.12 | perplexity:     8.35\n",
      "  500/  718 batches | 1384.06 ms/batch | lr: 0.0003553 | loss:  2.13 | perplexity:     8.39\n",
      "  600/  718 batches | 1439.63 ms/batch | lr: 0.0003135 | loss:  2.21 | perplexity:     9.10\n",
      "  700/  718 batches | 1455.92 ms/batch | lr: 0.0003553 | loss:  2.14 | perplexity:     8.53\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 1008.03 s | valid_loss:  2.46 | valid_perplexity:    11.65\n",
      "=====================================================================================\n",
      "Epoch  70) lr = 0.0003735\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  713 batches | 1500.43 ms/batch | lr: 0.0003735 | loss:  2.19 | perplexity:     8.92\n",
      "  200/  713 batches | 1479.90 ms/batch | lr: 0.0003528 | loss:  2.08 | perplexity:     7.97\n",
      "  300/  713 batches | 1489.60 ms/batch | lr: 0.0002905 | loss:  2.12 | perplexity:     8.33\n",
      "  400/  713 batches | 1451.72 ms/batch | lr: 0.000249 | loss:  2.11 | perplexity:     8.26\n",
      "  500/  713 batches | 1484.71 ms/batch | lr: 0.000415 | loss:  2.13 | perplexity:     8.40\n",
      "  600/  713 batches | 1473.55 ms/batch | lr: 0.0004565 | loss:  2.16 | perplexity:     8.64\n",
      "  700/  713 batches | 1504.31 ms/batch | lr: 0.0003735 | loss:  2.16 | perplexity:     8.71\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 1055.91 s | valid_loss:  2.48 | valid_perplexity:    11.93\n",
      "=====================================================================================\n",
      "Epoch  71) lr = 0.0003709\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1440.87 ms/batch | lr: 0.0002679 | loss:  2.20 | perplexity:     8.98\n",
      "  200/  716 batches | 1461.95 ms/batch | lr: 0.0003503 | loss:  2.09 | perplexity:     8.05\n",
      "  300/  716 batches | 1506.13 ms/batch | lr: 0.0003709 | loss:  2.10 | perplexity:     8.14\n",
      "  400/  716 batches | 1391.81 ms/batch | lr: 0.0003091 | loss:  2.04 | perplexity:     7.69\n",
      "  500/  716 batches | 1358.48 ms/batch | lr: 0.0003503 | loss:  2.10 | perplexity:     8.17\n",
      "  600/  716 batches | 1437.07 ms/batch | lr: 0.0003503 | loss:  2.16 | perplexity:     8.70\n",
      "  700/  716 batches | 1423.81 ms/batch | lr: 0.0003503 | loss:  2.16 | perplexity:     8.70\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 1022.96 s | valid_loss:  2.39 | valid_perplexity:    10.92\n",
      "=====================================================================================\n",
      "Epoch  72) lr = 0.0003683\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  720 batches | 1425.51 ms/batch | lr: 0.0003887 | loss:  2.13 | perplexity:     8.45\n",
      "  200/  720 batches | 1460.76 ms/batch | lr: 0.0003683 | loss:  2.09 | perplexity:     8.10\n",
      "  300/  720 batches | 1414.37 ms/batch | lr: 0.0003887 | loss:  2.04 | perplexity:     7.66\n",
      "  400/  720 batches | 1425.35 ms/batch | lr: 0.0004092 | loss:  2.08 | perplexity:     7.99\n",
      "  500/  720 batches | 1484.36 ms/batch | lr: 0.0004092 | loss:  2.14 | perplexity:     8.50\n",
      "  600/  720 batches | 1440.24 ms/batch | lr: 0.0003683 | loss:  2.10 | perplexity:     8.19\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    lr_scheduler.step()\n",
    "    print('Epoch {:3d}) lr = {:0.4g}'.format(epoch+1, np.mean(lr_scheduler.get_lr())))\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    elapsed = time.time() - start_time\n",
    "    val_loss = evaluate(val_data)\n",
    "    print('-' * 85)\n",
    "    print('Elapsed time: {:5.2f} s | valid_loss: {:5.2f} | valid_perplexity: {:8.2f}'.format(\n",
    "        elapsed, val_loss, np.exp(val_loss)\n",
    "    ))\n",
    "    print('=' * 85)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(test_data)\n",
    "print('test_loss: {:5.2f} | test_perplexity: {:8.2f}'.format(\n",
    "    test_loss, np.exp(test_loss)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some random words\n",
    "Just, like, y'know, as a test or whatever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "\n",
    "states = model.init_states(1)\n",
    "cur_word = Variable(torch.rand(1, 1).mul(ntokens).long(), volatile = True)\n",
    "gen_text = [int(cur_word)]\n",
    "\n",
    "for i in range(num_words):\n",
    "    output, hidden = model(cur_word, states)\n",
    "    word_weights = output.squeeze().exp()\n",
    "    word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "    gen_text.append(int(word_idx))\n",
    "    cur_word.data.fill_(word_idx)\n",
    "    \n",
    "# Print the words\n",
    "print(' '.join(gen_text))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
