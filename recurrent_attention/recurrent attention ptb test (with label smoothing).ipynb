{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import data\n",
    "from recurrent_attention import RecurrentAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overhead stuff\n",
    "\n",
    "Helper functions for batching, resetting hidden states, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "eval_batch_size = 10\n",
    "batch_size = 74\n",
    "seq_len = 18\n",
    "dropout = 0.1\n",
    "clip = 0.1\n",
    "lr = 0.01\n",
    "warmup_steps = 15\n",
    "smooth_labels = False\n",
    "\n",
    "epochs = 100\n",
    "log_interval = 100  # Print log every `log_interval` batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "embed_size = 256\n",
    "encode_size = 128\n",
    "h_size = 64\n",
    "attn_out_size = 128\n",
    "decode_size = 256\n",
    "n_layers = 2\n",
    "attn_rnn_layers = 1\n",
    "bidirectional_attn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from sequential data, `batchify` arranges the dataset into columns.\n",
    "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
    "# ┌ a g m s ┐\n",
    "# │ b h n t │\n",
    "# │ c i o u │\n",
    "# │ d j p v │\n",
    "# │ e k q w │\n",
    "# └ f l r x ┘.\n",
    "# These columns are treated as independent by the model, which means that the\n",
    "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
    "# batch processing.\n",
    "def batchify(data, batch_size):\n",
    "    # Work out how cleanly we can divide the dataset into batches\n",
    "    nbatches = data.size(0) // batch_size\n",
    "    # Trim off any extra elements that wouldn't cleanly fit\n",
    "    data = data.narrow(0, 0, nbatches * batch_size)\n",
    "    # Evenly divide the data across the batches\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    return data\n",
    "\n",
    "# Wraps hidden states into new Variables to detach them from their history\n",
    "def repackage_hidden(h):\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "# `get_batch` subdivides the source data into chunks of the specified length.\n",
    "# E.g., using the example for the `batchify` function above and a length of 2,\n",
    "# we'd get the following two Variables for i = 0:\n",
    "# ┌ a g m s ┐ ┌ b h n t ┐\n",
    "# └ b h n t ┘ └ c i o u ┘\n",
    "# Note that despite the name of the function, the subdivison of data is not\n",
    "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
    "# by the `batchify` function. The chunks are along dimension 0, corresponding\n",
    "# to the `seq_len` dimension in the LSTM.\n",
    "def get_batch(source, i, seq_len, evaluate = False):\n",
    "    seq_len = min(seq_len, len(source) - 1 - i)\n",
    "    data = Variable(source[i : i+seq_len], volatile = evaluate)\n",
    "    target = Variable(source[i+1 : i+1+seq_len].view(-1), volatile = evaluate)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label smoothing class for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, padding_idx = None, smoothing = 0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        if self.padding_idx is not None:\n",
    "            true_dist[:, self.padding_idx] = 0\n",
    "            mask = torch.nonzero(target.data == self.padding_idx)\n",
    "            if mask.dim() > 0:\n",
    "                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate scheduler that sets the learning rate factor according to:\n",
    "\n",
    "$$\\text{lr} = d_{\\text{model}}^{-0.5}\\cdot\\min{(\\text{epoch}^{-0.5}, \\text{epoch}\\cdot\\text{warmup}^{-1.5})}$$\n",
    "\n",
    "This corresponds to increasing the learning rate linearly for the first $\\text{warmup}$ epochs, then decreasing it proportionally to the inverse square root of the epoch number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler(h_size, warmup, optimizer):\n",
    "    lrate = lambda e: h_size**(-0.5) * min((e+1)**(-0.5), (e+1) * warmup**(-1.5))\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e23b982c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e239916080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrate = lambda factor, h_size, warmup: lambda e: h_size**(-0.5) * min(e**(-0.5), e * warmup**(-1.5))\n",
    "opts = [\n",
    "    lrate(512, 40), \n",
    "    lrate(512, 80),\n",
    "    lrate(256, 40),\n",
    "    lrate(embed_size, warmup_steps),\n",
    "]\n",
    "plt.plot(np.arange(1, 200), [[opt(i) for opt in opts] for i in range(1, 200)])\n",
    "plt.legend([\"512:40\", \"512:80\", \"256:40\", \"%d:%d\" % (embed_size, warmup_steps)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.Corpus('./data/ptb')\n",
    "ntokens = len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab,\n",
    "                 embed_size, encode_size, h_size,\n",
    "                 attn_out_size, decode_size, n_layers,\n",
    "                 attn_rnn_layers, bidirectional_attn,\n",
    "                 project = True, dropout = 0.1):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.embed_size = embed_size\n",
    "        self.encode_size = encode_size\n",
    "        self.h_size = h_size\n",
    "        self.attn_out_size = attn_out_size\n",
    "        self.decode_size = decode_size\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_rnn_layers = attn_rnn_layers\n",
    "        self.bidirectional_attn = bidirectional_attn\n",
    "        self.project = project\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embed = nn.Embedding(src_vocab, embed_size)\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size = embed_size, hidden_size = encode_size,\n",
    "            num_layers = n_layers, dropout = dropout\n",
    "        )\n",
    "        self.attn = RecurrentAttention(\n",
    "            in_size = encode_size, h_size = h_size, out_size = attn_out_size,\n",
    "            dropout = dropout, num_rnn_layers = attn_rnn_layers,\n",
    "            bidirectional = bidirectional_attn\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size = attn_out_size, hidden_size = decode_size,\n",
    "            num_layers = n_layers, dropout = dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(decode_size, tgt_vocab)\n",
    "        if project and src_vocab == tgt_vocab and embed_size == decode_size:\n",
    "            self.decoder.weight = self.embed.weight\n",
    "        \n",
    "    def init(self):\n",
    "        for subnet in [self.encoder, self.decoder]:\n",
    "            for p in subnet.parameters():\n",
    "                if p.dim() > 1:\n",
    "                    nn.init.xavier_normal(p)\n",
    "                else:\n",
    "                    p.data.fill_(0)\n",
    "        for p in self.linear.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform(p)\n",
    "            else:\n",
    "                p.data.fill_(0)\n",
    "        self.attn.init()\n",
    "        \n",
    "    def init_states(self, batch_size):\n",
    "        encoder_states = (\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.encode_size)),\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.encode_size))\n",
    "        )\n",
    "        attn_states = self.attn.init_rnn_states(batch_size)\n",
    "        decoder_states = (\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.decode_size)),\n",
    "            Variable(torch.zeros(self.n_layers, batch_size, self.decode_size))\n",
    "        )\n",
    "        return encoder_states, attn_states, decoder_states\n",
    "    \n",
    "    def forward(self, inputs, states):\n",
    "        enc_states, attn_states, dec_states = states\n",
    "        relu = nn.ReLU()\n",
    "        log_softmax = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "        embeddings = self.embed(inputs) * np.sqrt(self.embed_size)\n",
    "        enc_out, new_enc_states = self.encoder(self.drop(embeddings))\n",
    "        attn_out, new_attn_states = self.attn(enc_out, attn_states)\n",
    "        dec_out, new_dec_states = self.decoder(relu(attn_out))\n",
    "        output = self.linear(dec_out)\n",
    "        if smooth_labels:\n",
    "            output = log_softmax(output)\n",
    "        return output, (new_enc_states, new_attn_states, new_dec_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model, criterion, optimizer, and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    ntokens, ntokens, embed_size, encode_size, h_size,\n",
    "    attn_out_size, decode_size, n_layers, attn_rnn_layers,\n",
    "    bidirectional_attn, dropout = dropout\n",
    ")\n",
    "if smooth_labels:\n",
    "    criterion = LabelSmoothing(ntokens, smoothing = 0.1)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr = lr, betas = (0.9, 0.98), eps = 1e-9\n",
    ")\n",
    "lr_scheduler = get_lr_scheduler(embed_size, warmup_steps, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 6422609\n"
     ]
    }
   ],
   "source": [
    "nparams = sum([p.numel() for p in model.parameters()])\n",
    "print('Model parameters: %d' % nparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Ready the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = batchify(corpus.train, batch_size)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Use random length sequences\n",
    "    seq_lens = []\n",
    "    tot_len = 0\n",
    "    jitter = 0.15 * seq_len\n",
    "    while tot_len < train_data.size(0) - 2:\n",
    "        if train_data.size(0) - tot_len - 2 <= seq_len + jitter:\n",
    "            slen = train_data.size(0) - tot_len - 2\n",
    "        else:\n",
    "            slen = int(np.random.normal(seq_len, jitter))\n",
    "            if slen <= 0:\n",
    "                slen = seq_len    # eh\n",
    "            if tot_len + slen >= train_data.size(0) - jitter - 2:\n",
    "                slen = train_data.size(0) - tot_len - 2\n",
    "        seq_lens.append(slen)\n",
    "        tot_len += slen\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    # Initialize RNN states\n",
    "    states = model.init_states(batch_size)\n",
    "    # Prep metainfo\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch, i in enumerate(np.cumsum(seq_lens)):\n",
    "        # Get training data\n",
    "        data, targets = get_batch(train_data, i, seq_lens[batch])\n",
    "        # Repackage the hidden states\n",
    "        states = repackage_hidden(states)\n",
    "        # Zero out gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Run the model forward\n",
    "        output, states = model(data, states)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        # Propagate loss gradient backwards\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "        # Scale the batch learning rate so that shorter sequences aren't \"stronger\"\n",
    "        scaled_lr = [\n",
    "            r*seq_lens[batch] / seq_len for r in lr_scheduler.get_lr()\n",
    "        ]\n",
    "        for param_group, r in zip(optimizer.param_groups, scaled_lr):\n",
    "            param_group['lr'] = r\n",
    "        # Adjust parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get some metainfo\n",
    "        total_loss += loss.data\n",
    "        lr = np.mean(scaled_lr)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss[0] / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('{:5d}/{:5d} batches | {:5.2f} ms/batch | lr: {:0.4g} | loss: {:5.2f} | perplexity: {:8.2f}'.format(\n",
    "                batch, len(seq_lens), elapsed * 1000/log_interval, lr, cur_loss, np.exp(cur_loss)\n",
    "            ))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_src):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    states = model.init_states(eval_batch_size)\n",
    "    for i in range(0, data_src.size(0) - 1, seq_len):\n",
    "        # Get data\n",
    "        data, targets = get_batch(data_src, i, seq_len, evaluate = True)\n",
    "        # Repackage the hidden states\n",
    "        states = repackage_hidden(states)\n",
    "        # Evaluate\n",
    "        output, states = model(data, states)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        total_loss += len(data) * loss.data\n",
    "    return total_loss[0] / len(data_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1) lr = 5.379e-05\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1145.74 ms/batch | lr: 6.276e-05 | loss:  9.00 | perplexity:  8080.81\n",
      "  200/  717 batches | 1065.42 ms/batch | lr: 4.483e-05 | loss:  7.23 | perplexity:  1376.84\n",
      "  300/  717 batches | 1139.16 ms/batch | lr: 4.483e-05 | loss:  6.68 | perplexity:   794.16\n",
      "  400/  717 batches | 1171.78 ms/batch | lr: 3.885e-05 | loss:  6.61 | perplexity:   739.43\n",
      "  500/  717 batches | 1196.25 ms/batch | lr: 3.885e-05 | loss:  6.59 | perplexity:   728.44\n",
      "  600/  717 batches | 1243.73 ms/batch | lr: 4.781e-05 | loss:  6.58 | perplexity:   721.90\n",
      "  700/  717 batches | 1247.88 ms/batch | lr: 5.379e-05 | loss:  6.60 | perplexity:   734.10\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 839.87 s | valid_loss:  6.56 | valid_perplexity:   702.97\n",
      "=====================================================================================\n",
      "Epoch   2) lr = 0.0001076\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1491.21 ms/batch | lr: 0.0001375 | loss:  6.64 | perplexity:   761.47\n",
      "  200/  717 batches | 1157.12 ms/batch | lr: 0.0001016 | loss:  6.56 | perplexity:   702.80\n",
      "  300/  717 batches | 1293.22 ms/batch | lr: 0.0001255 | loss:  6.56 | perplexity:   705.15\n",
      "  400/  717 batches | 1194.73 ms/batch | lr: 0.0001375 | loss:  6.59 | perplexity:   728.09\n",
      "  500/  717 batches | 1327.58 ms/batch | lr: 0.0001195 | loss:  6.58 | perplexity:   720.90\n",
      "  600/  717 batches | 1292.69 ms/batch | lr: 9.563e-05 | loss:  6.57 | perplexity:   716.59\n",
      "  700/  717 batches | 1384.21 ms/batch | lr: 7.77e-05 | loss:  6.58 | perplexity:   722.22\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 938.44 s | valid_loss:  6.57 | valid_perplexity:   710.51\n",
      "=====================================================================================\n",
      "Epoch   3) lr = 0.0001614\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1192.83 ms/batch | lr: 0.0001434 | loss:  6.61 | perplexity:   743.53\n",
      "  200/  716 batches | 1160.84 ms/batch | lr: 0.0001703 | loss:  6.52 | perplexity:   679.70\n",
      "  300/  716 batches | 1186.48 ms/batch | lr: 0.0001703 | loss:  6.51 | perplexity:   670.71\n",
      "  400/  716 batches | 1120.30 ms/batch | lr: 0.0001434 | loss:  6.51 | perplexity:   671.94\n",
      "  500/  716 batches | 1183.23 ms/batch | lr: 0.0001793 | loss:  6.48 | perplexity:   653.40\n",
      "  600/  716 batches | 1188.24 ms/batch | lr: 0.0001165 | loss:  6.45 | perplexity:   633.28\n",
      "  700/  716 batches | 1175.85 ms/batch | lr: 0.0001614 | loss:  6.45 | perplexity:   630.71\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 835.76 s | valid_loss:  6.43 | valid_perplexity:   620.49\n",
      "=====================================================================================\n",
      "Epoch   4) lr = 0.0002152\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  725 batches | 1156.22 ms/batch | lr: 0.0002032 | loss:  6.47 | perplexity:   644.30\n",
      "  200/  725 batches | 1109.79 ms/batch | lr: 0.0002271 | loss:  6.37 | perplexity:   583.85\n",
      "  300/  725 batches | 1158.49 ms/batch | lr: 0.0002032 | loss:  6.36 | perplexity:   578.02\n",
      "  400/  725 batches | 1266.07 ms/batch | lr: 0.0002391 | loss:  6.37 | perplexity:   583.92\n",
      "  500/  725 batches | 1189.98 ms/batch | lr: 0.0001554 | loss:  6.35 | perplexity:   572.61\n",
      "  600/  725 batches | 1157.75 ms/batch | lr: 0.0001913 | loss:  6.33 | perplexity:   561.40\n",
      "  700/  725 batches | 1144.78 ms/batch | lr: 0.0002152 | loss:  6.32 | perplexity:   557.56\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 841.96 s | valid_loss:  6.31 | valid_perplexity:   551.06\n",
      "=====================================================================================\n",
      "Epoch   5) lr = 0.000269\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1206.15 ms/batch | lr: 0.0002241 | loss:  6.34 | perplexity:   566.72\n",
      "  200/  718 batches | 1130.22 ms/batch | lr: 0.0002839 | loss:  6.24 | perplexity:   512.12\n",
      "  300/  718 batches | 1110.22 ms/batch | lr: 0.0002988 | loss:  6.22 | perplexity:   500.21\n",
      "  400/  718 batches | 1111.88 ms/batch | lr: 0.0001942 | loss:  6.24 | perplexity:   511.52\n",
      "  500/  718 batches | 1109.99 ms/batch | lr: 0.0003138 | loss:  6.20 | perplexity:   493.23\n",
      "  600/  718 batches | 1143.63 ms/batch | lr: 0.000269 | loss:  6.17 | perplexity:   476.26\n",
      "  700/  718 batches | 1103.30 ms/batch | lr: 0.0002391 | loss:  6.18 | perplexity:   481.13\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 809.81 s | valid_loss:  6.15 | valid_perplexity:   470.81\n",
      "=====================================================================================\n",
      "Epoch   6) lr = 0.0003227\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  724 batches | 1134.85 ms/batch | lr: 0.0003048 | loss:  6.19 | perplexity:   486.06\n",
      "  200/  724 batches | 1093.02 ms/batch | lr: 0.0003227 | loss:  6.07 | perplexity:   433.92\n",
      "  300/  724 batches | 1104.12 ms/batch | lr: 0.0003765 | loss:  6.06 | perplexity:   428.64\n",
      "  400/  724 batches | 1108.69 ms/batch | lr: 0.0003407 | loss:  6.08 | perplexity:   437.90\n",
      "  500/  724 batches | 1101.94 ms/batch | lr: 0.0003765 | loss:  6.05 | perplexity:   425.52\n",
      "  600/  724 batches | 1089.96 ms/batch | lr: 0.000269 | loss:  6.01 | perplexity:   408.73\n",
      "  700/  724 batches | 1051.43 ms/batch | lr: 0.000251 | loss:  6.00 | perplexity:   405.29\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 790.04 s | valid_loss:  5.99 | valid_perplexity:   397.63\n",
      "=====================================================================================\n",
      "Epoch   7) lr = 0.0003765\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  717 batches | 1097.01 ms/batch | lr: 0.0004184 | loss:  6.02 | perplexity:   411.90\n",
      "  200/  717 batches | 1141.65 ms/batch | lr: 0.0002929 | loss:  5.90 | perplexity:   365.24\n",
      "  300/  717 batches | 1100.50 ms/batch | lr: 0.0003347 | loss:  5.88 | perplexity:   358.16\n",
      "  400/  717 batches | 1077.90 ms/batch | lr: 0.0003765 | loss:  5.89 | perplexity:   363.02\n",
      "  500/  717 batches | 1078.39 ms/batch | lr: 0.0003975 | loss:  5.85 | perplexity:   348.65\n",
      "  600/  717 batches | 1113.79 ms/batch | lr: 0.0003975 | loss:  5.85 | perplexity:   347.09\n",
      "  700/  717 batches | 1122.99 ms/batch | lr: 0.0003556 | loss:  5.83 | perplexity:   339.95\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 789.17 s | valid_loss:  5.82 | valid_perplexity:   336.16\n",
      "=====================================================================================\n",
      "Epoch   8) lr = 0.0004303\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1078.04 ms/batch | lr: 0.0004064 | loss:  5.83 | perplexity:   341.36\n",
      "  200/  719 batches | 1115.24 ms/batch | lr: 0.0004781 | loss:  5.73 | perplexity:   308.03\n",
      "  300/  719 batches | 1100.60 ms/batch | lr: 0.0005021 | loss:  5.69 | perplexity:   295.54\n",
      "  400/  719 batches | 1064.04 ms/batch | lr: 0.0004542 | loss:  5.72 | perplexity:   304.01\n",
      "  500/  719 batches | 1090.93 ms/batch | lr: 0.0004781 | loss:  5.67 | perplexity:   289.38\n",
      "  600/  719 batches | 1129.74 ms/batch | lr: 0.0004064 | loss:  5.67 | perplexity:   288.76\n",
      "  700/  719 batches | 1082.80 ms/batch | lr: 0.0003825 | loss:  5.66 | perplexity:   286.12\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 783.00 s | valid_loss:  5.66 | valid_perplexity:   288.49\n",
      "=====================================================================================\n",
      "Epoch   9) lr = 0.0004841\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1120.72 ms/batch | lr: 0.0004034 | loss:  5.66 | perplexity:   288.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200/  715 batches | 1093.49 ms/batch | lr: 0.0004303 | loss:  5.53 | perplexity:   252.82\n",
      "  300/  715 batches | 1082.68 ms/batch | lr: 0.0005648 | loss:  5.50 | perplexity:   245.03\n",
      "  400/  715 batches | 1153.28 ms/batch | lr: 0.0005379 | loss:  5.56 | perplexity:   259.93\n",
      "  500/  715 batches | 1072.52 ms/batch | lr: 0.0004034 | loss:  5.49 | perplexity:   243.29\n",
      "  600/  715 batches | 1097.76 ms/batch | lr: 0.0004841 | loss:  5.47 | perplexity:   238.49\n",
      "  700/  715 batches | 1101.78 ms/batch | lr: 0.0003496 | loss:  5.46 | perplexity:   234.74\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 784.66 s | valid_loss:  5.52 | valid_perplexity:   250.65\n",
      "=====================================================================================\n",
      "Epoch  10) lr = 0.0005379\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1095.47 ms/batch | lr: 0.0003885 | loss:  5.48 | perplexity:   240.25\n",
      "  200/  719 batches | 1143.27 ms/batch | lr: 0.0006575 | loss:  5.37 | perplexity:   214.73\n",
      "  300/  719 batches | 1100.61 ms/batch | lr: 0.0004483 | loss:  5.33 | perplexity:   207.10\n",
      "  400/  719 batches | 1077.01 ms/batch | lr: 0.0004781 | loss:  5.36 | perplexity:   212.98\n",
      "  500/  719 batches | 1084.56 ms/batch | lr: 0.0006575 | loss:  5.34 | perplexity:   209.09\n",
      "  600/  719 batches | 1087.56 ms/batch | lr: 0.000508 | loss:  5.29 | perplexity:   199.12\n",
      "  700/  719 batches | 1114.07 ms/batch | lr: 0.0003287 | loss:  5.29 | perplexity:   198.43\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 787.58 s | valid_loss:  5.35 | valid_perplexity:   209.85\n",
      "=====================================================================================\n",
      "Epoch  11) lr = 0.0005917\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1114.85 ms/batch | lr: 0.0004602 | loss:  5.30 | perplexity:   199.96\n",
      "  200/  715 batches | 1077.15 ms/batch | lr: 0.0005588 | loss:  5.19 | perplexity:   180.33\n",
      "  300/  715 batches | 1099.69 ms/batch | lr: 0.000526 | loss:  5.16 | perplexity:   173.44\n",
      "  400/  715 batches | 1103.45 ms/batch | lr: 0.0003945 | loss:  5.21 | perplexity:   183.57\n",
      "  500/  715 batches | 1089.60 ms/batch | lr: 0.0007232 | loss:  5.12 | perplexity:   167.81\n",
      "  600/  715 batches | 1121.83 ms/batch | lr: 0.000526 | loss:  5.15 | perplexity:   171.85\n",
      "  700/  715 batches | 1104.57 ms/batch | lr: 0.0006246 | loss:  5.12 | perplexity:   167.40\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 785.50 s | valid_loss:  5.23 | valid_perplexity:   186.84\n",
      "=====================================================================================\n",
      "Epoch  12) lr = 0.0006455\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1104.98 ms/batch | lr: 0.0004662 | loss:  5.12 | perplexity:   168.03\n",
      "  200/  721 batches | 1052.32 ms/batch | lr: 0.0006096 | loss:  4.96 | perplexity:   142.64\n",
      "  300/  721 batches | 1149.94 ms/batch | lr: 0.0004303 | loss:  5.02 | perplexity:   150.73\n",
      "  400/  721 batches | 1072.84 ms/batch | lr: 0.0006814 | loss:  5.01 | perplexity:   149.53\n",
      "  500/  721 batches | 1091.60 ms/batch | lr: 0.0006814 | loss:  4.99 | perplexity:   146.43\n",
      "  600/  721 batches | 1085.08 ms/batch | lr: 0.0007172 | loss:  4.95 | perplexity:   141.02\n",
      "  700/  721 batches | 1108.87 ms/batch | lr: 0.0006096 | loss:  4.95 | perplexity:   141.72\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 787.58 s | valid_loss:  5.08 | valid_perplexity:   160.65\n",
      "=====================================================================================\n",
      "Epoch  13) lr = 0.0006993\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  716 batches | 1143.37 ms/batch | lr: 0.000505 | loss:  4.97 | perplexity:   143.88\n",
      "  200/  716 batches | 1104.80 ms/batch | lr: 0.0005827 | loss:  4.88 | perplexity:   131.02\n",
      "  300/  716 batches | 1090.30 ms/batch | lr: 0.0008158 | loss:  4.82 | perplexity:   123.56\n",
      "  400/  716 batches | 1133.39 ms/batch | lr: 0.0006604 | loss:  4.88 | perplexity:   131.58\n",
      "  500/  716 batches | 1132.34 ms/batch | lr: 0.0006604 | loss:  4.82 | perplexity:   123.64\n",
      "  600/  716 batches | 1143.52 ms/batch | lr: 0.0006993 | loss:  4.83 | perplexity:   125.35\n",
      "  700/  716 batches | 1134.22 ms/batch | lr: 0.0006604 | loss:  4.79 | perplexity:   120.02\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 804.13 s | valid_loss:  4.97 | valid_perplexity:   144.30\n",
      "=====================================================================================\n",
      "Epoch  14) lr = 0.0007531\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  715 batches | 1111.50 ms/batch | lr: 0.0006694 | loss:  4.80 | perplexity:   121.60\n",
      "  200/  715 batches | 1124.09 ms/batch | lr: 0.0008786 | loss:  4.72 | perplexity:   111.93\n",
      "  300/  715 batches | 1121.59 ms/batch | lr: 0.0008368 | loss:  4.68 | perplexity:   108.01\n",
      "  400/  715 batches | 1110.95 ms/batch | lr: 0.0007949 | loss:  4.70 | perplexity:   109.78\n",
      "  500/  715 batches | 1134.73 ms/batch | lr: 0.0007112 | loss:  4.68 | perplexity:   107.26\n",
      "  600/  715 batches | 1102.78 ms/batch | lr: 0.0007112 | loss:  4.65 | perplexity:   104.59\n",
      "  700/  715 batches | 1102.53 ms/batch | lr: 0.0007112 | loss:  4.66 | perplexity:   105.37\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 796.33 s | valid_loss:  4.73 | valid_perplexity:   112.81\n",
      "=====================================================================================\n",
      "Epoch  15) lr = 0.0008069\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  719 batches | 1111.58 ms/batch | lr: 0.000762 | loss:  4.67 | perplexity:   106.34\n",
      "  200/  719 batches | 1097.58 ms/batch | lr: 0.0007172 | loss:  4.56 | perplexity:    95.66\n",
      "  300/  719 batches | 1094.34 ms/batch | lr: 0.0008069 | loss:  4.50 | perplexity:    90.25\n",
      "  400/  719 batches | 1077.69 ms/batch | lr: 0.0007172 | loss:  4.52 | perplexity:    92.02\n",
      "  500/  719 batches | 1107.48 ms/batch | lr: 0.0008069 | loss:  4.54 | perplexity:    93.85\n",
      "  600/  719 batches | 1082.19 ms/batch | lr: 0.0007172 | loss:  4.50 | perplexity:    89.84\n",
      "  700/  719 batches | 1110.37 ms/batch | lr: 0.000762 | loss:  4.51 | perplexity:    90.63\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 787.44 s | valid_loss:  4.62 | valid_perplexity:   101.66\n",
      "=====================================================================================\n",
      "Epoch  16) lr = 0.0007813\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  718 batches | 1135.55 ms/batch | lr: 0.0007378 | loss:  4.52 | perplexity:    92.08\n",
      "  200/  718 batches | 1069.86 ms/batch | lr: 0.0009115 | loss:  4.36 | perplexity:    78.11\n",
      "  300/  718 batches | 1093.39 ms/batch | lr: 0.0007378 | loss:  4.35 | perplexity:    77.32\n",
      "  400/  718 batches | 1108.08 ms/batch | lr: 0.0009549 | loss:  4.39 | perplexity:    80.74\n",
      "  500/  718 batches | 1125.93 ms/batch | lr: 0.0007378 | loss:  4.41 | perplexity:    82.52\n",
      "  600/  718 batches | 1135.87 ms/batch | lr: 0.000651 | loss:  4.34 | perplexity:    76.63\n",
      "  700/  718 batches | 1100.20 ms/batch | lr: 0.0008247 | loss:  4.33 | perplexity:    76.21\n",
      "-------------------------------------------------------------------------------------\n",
      "Elapsed time: 795.16 s | valid_loss:  4.47 | valid_perplexity:    87.53\n",
      "=====================================================================================\n",
      "Epoch  17) lr = 0.0007579\n",
      "-------------------------------------------------------------------------------------\n",
      "  100/  721 batches | 1145.64 ms/batch | lr: 0.0006737 | loss:  4.32 | perplexity:    75.15\n",
      "  200/  721 batches | 1135.40 ms/batch | lr: 0.0007579 | loss:  4.22 | perplexity:    67.74\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    lr_scheduler.step()\n",
    "    print('Epoch {:3d}) lr = {:0.4g}'.format(epoch+1, np.mean(lr_scheduler.get_lr())))\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    elapsed = time.time() - start_time\n",
    "    val_loss = evaluate(val_data)\n",
    "    print('-' * 85)\n",
    "    print('Elapsed time: {:5.2f} s | valid_loss: {:5.2f} | valid_perplexity: {:8.2f}'.format(\n",
    "        elapsed, val_loss, np.exp(val_loss)\n",
    "    ))\n",
    "    print('=' * 85)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(test_data)\n",
    "print('test_loss: {:5.2f} | test_perplexity: {:8.2f}'.format(\n",
    "    test_loss, np.exp(test_loss)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
